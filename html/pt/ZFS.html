<!DOCTYPE html>
<html class="client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-0 vector-feature-client-preferences-disabled vector-feature-client-prefs-pinned-disabled vector-feature-night-mode-disabled skin-theme-clientpref-day vector-toc-available" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>ZFS (Português) - ArchWiki</title>
<link rel="stylesheet" href="../ArchWikiOffline.css">
<meta name="ResourceLoaderDynamicStyles" content="">
<meta name="generator" content="MediaWiki 1.42.1">
<meta name="referrer" content="no-referrer-when-downgrade">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=0.25, maximum-scale=5.0">
<link rel="icon" href="/favicon.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/opensearch_desc.php" title="ArchWiki (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://wiki.archlinux.org/api.php?action=rsd">
<link rel="license" href="https://www.gnu.org/copyleft/fdl.html">
<link rel="alternate" type="application/atom+xml" title="ArchWiki Atom feed" href="/index.php?title=Special:RecentChanges&amp;feed=atom">
</head>
<body class="skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-ZFS_Português rootpage-ZFS_Português skin-vector-2022 action-view skin--responsive">
<a class="mw-jump-link" href="#bodyContent">Jump to content</a>
<div class="vector-header-container">
	</div>
<div class="mw-page-container">
	<div class="mw-page-container-inner">
		<div class="vector-column-start">
			<div class="vector-main-menu-container">
		</div>
	<div class="vector-sticky-pinned-container">
				<nav id="mw-panel-toc" role="navigation" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container vector-toc-landmark">
					<div id="vector-toc-pinned-container" class="vector-pinned-container">
					<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned" data-feature-name="toc-pinned" data-pinnable-element-id="vector-toc">
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text" class="vector-toc-list-item vector-toc-level-1">
			<a href="#" class="vector-toc-link">
				<div class="vector-toc-text">Beginning</div>
			</a>
		</li>
		<li id="toc-Instalação" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Instala%C3%A7%C3%A3o">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">1</span>Instalação</div>
		</a>
		
			<button aria-controls="toc-Instalação-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Instalação subsection</span>
			</button>
		
		<ul id="toc-Instalação-sublist" class="vector-toc-list">
			<li id="toc-Geral" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Geral">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">1.1</span>Geral</div>
			</a>
			
			<ul id="toc-Geral-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-ZFS_na_raiz" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#ZFS_na_raiz">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">1.2</span>ZFS na raiz</div>
			</a>
			
			<ul id="toc-ZFS_na_raiz-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-DKMS" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#DKMS">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">1.3</span>DKMS</div>
			</a>
			
			<ul id="toc-DKMS-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Experimentos_com_ZFS" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Experimentos_com_ZFS">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">2</span>Experimentos com ZFS</div>
		</a>
		
		<ul id="toc-Experimentos_com_ZFS-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Configuração" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Configura%C3%A7%C3%A3o">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">3</span>Configuração</div>
		</a>
		
			<button aria-controls="toc-Configuração-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Configuração subsection</span>
			</button>
		
		<ul id="toc-Configuração-sublist" class="vector-toc-list">
			<li id="toc-Inicialização_automática" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Inicializa%C3%A7%C3%A3o_autom%C3%A1tica">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.1</span>Inicialização automática</div>
			</a>
			
			<ul id="toc-Inicialização_automática-sublist" class="vector-toc-list">
				<li id="toc-Usando_zfs-mount.service" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Usando_zfs-mount.service">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.1.1</span>Usando zfs-mount.service</div>
			</a>
			
			<ul id="toc-Usando_zfs-mount.service-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Usando_zfs-mount-generator" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Usando_zfs-mount-generator">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.1.2</span>Usando zfs-mount-generator</div>
			</a>
			
			<ul id="toc-Usando_zfs-mount-generator-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Pools_de_Armazenamento" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Pools_de_Armazenamento">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">4</span>Pools de Armazenamento</div>
		</a>
		
			<button aria-controls="toc-Pools_de_Armazenamento-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Pools de Armazenamento subsection</span>
			</button>
		
		<ul id="toc-Pools_de_Armazenamento-sublist" class="vector-toc-list">
			<li id="toc-Identificando_discos" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Identificando_discos">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.1</span>Identificando discos</div>
			</a>
			
			<ul id="toc-Identificando_discos-sublist" class="vector-toc-list">
				<li id="toc-Utilizando_rótulos_GPT" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Utilizando_r%C3%B3tulos_GPT">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.1.1</span>Utilizando rótulos GPT</div>
			</a>
			
			<ul id="toc-Utilizando_rótulos_GPT-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Criando_pools_ZFS" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Criando_pools_ZFS">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2</span>Criando pools ZFS</div>
			</a>
			
			<ul id="toc-Criando_pools_ZFS-sublist" class="vector-toc-list">
				<li id="toc-Discos_com_formatação_avançada" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Discos_com_formata%C3%A7%C3%A3o_avan%C3%A7ada">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2.1</span>Discos com formatação avançada</div>
			</a>
			
			<ul id="toc-Discos_com_formatação_avançada-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Criação_de_pool_compatível_com_GRUB" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Cria%C3%A7%C3%A3o_de_pool_compat%C3%ADvel_com_GRUB">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2.2</span>Criação de pool compatível com GRUB</div>
			</a>
			
			<ul id="toc-Criação_de_pool_compatível_com_GRUB-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Verificando_status_da_pool" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Verificando_status_da_pool">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.3</span>Verificando status da pool</div>
			</a>
			
			<ul id="toc-Verificando_status_da_pool-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Importando_por_id_uma_pool_criada" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Importando_por_id_uma_pool_criada">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.4</span>Importando por id uma pool criada</div>
			</a>
			
			<ul id="toc-Importando_por_id_uma_pool_criada-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Destruir_uma_pool_de_armazenamento" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Destruir_uma_pool_de_armazenamento">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.5</span>Destruir uma pool de armazenamento</div>
			</a>
			
			<ul id="toc-Destruir_uma_pool_de_armazenamento-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Exportar_uma_pool_de_armazenamento" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Exportar_uma_pool_de_armazenamento">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.6</span>Exportar uma pool de armazenamento</div>
			</a>
			
			<ul id="toc-Exportar_uma_pool_de_armazenamento-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Estendendo_uma_pool_existente" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Estendendo_uma_pool_existente">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.7</span>Estendendo uma pool existente</div>
			</a>
			
			<ul id="toc-Estendendo_uma_pool_existente-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Renomear_uma_pool" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Renomear_uma_pool">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.8</span>Renomear uma pool</div>
			</a>
			
			<ul id="toc-Renomear_uma_pool-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Definir_um_ponto_de_montagem_diferente" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Definir_um_ponto_de_montagem_diferente">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.9</span>Definir um ponto de montagem diferente</div>
			</a>
			
			<ul id="toc-Definir_um_ponto_de_montagem_diferente-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Criando_datasets" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Criando_datasets">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">5</span>Criando datasets</div>
		</a>
		
			<button aria-controls="toc-Criando_datasets-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Criando datasets subsection</span>
			</button>
		
		<ul id="toc-Criando_datasets-sublist" class="vector-toc-list">
			<li id="toc-Criptografia_nativa" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Criptografia_nativa">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.1</span>Criptografia nativa</div>
			</a>
			
			<ul id="toc-Criptografia_nativa-sublist" class="vector-toc-list">
				<li id="toc-Desbloquear_durante_a_inicialização" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Desbloquear_durante_a_inicializa%C3%A7%C3%A3o">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.1.1</span>Desbloquear durante a inicialização</div>
			</a>
			
			<ul id="toc-Desbloquear_durante_a_inicialização-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Volume_de_swap" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Volume_de_swap">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2</span>Volume de swap</div>
			</a>
			
			<ul id="toc-Volume_de_swap-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Listas_de_Controle_de_Acesso" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Listas_de_Controle_de_Acesso">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.3</span>Listas de Controle de Acesso</div>
			</a>
			
			<ul id="toc-Listas_de_Controle_de_Acesso-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Bancos_de_dados" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Bancos_de_dados">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.4</span>Bancos de dados</div>
			</a>
			
			<ul id="toc-Bancos_de_dados-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-/tmp" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#/tmp">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.5</span>/tmp</div>
			</a>
			
			<ul id="toc-/tmp-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Refinamento" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Refinamento">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">6</span>Refinamento</div>
		</a>
		
			<button aria-controls="toc-Refinamento-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Refinamento subsection</span>
			</button>
		
		<ul id="toc-Refinamento-sublist" class="vector-toc-list">
			<li id="toc-Geral_2" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Geral_2">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.1</span>Geral</div>
			</a>
			
			<ul id="toc-Geral_2-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Esfregar" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Esfregar">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.2</span>Esfregar</div>
			</a>
			
			<ul id="toc-Esfregar-sublist" class="vector-toc-list">
				<li id="toc-Com_que_frequência_devo_fazer_isto?" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Com_que_frequ%C3%AAncia_devo_fazer_isto?">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.2.1</span>Com que frequência devo fazer isto?</div>
			</a>
			
			<ul id="toc-Com_que_frequência_devo_fazer_isto?-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Iniciar_com_serviço_ou_timer" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Iniciar_com_servi%C3%A7o_ou_timer">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.2.2</span>Iniciar com serviço ou timer</div>
			</a>
			
			<ul id="toc-Iniciar_com_serviço_ou_timer-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Cache_em_SSD" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Cache_em_SSD">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.3</span>Cache em SSD</div>
			</a>
			
			<ul id="toc-Cache_em_SSD-sublist" class="vector-toc-list">
				<li id="toc-SLOG" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#SLOG">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.3.1</span>SLOG</div>
			</a>
			
			<ul id="toc-SLOG-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-L2ARC" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#L2ARC">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.3.2</span>L2ARC</div>
			</a>
			
			<ul id="toc-L2ARC-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-ZVOLs" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#ZVOLs">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.4</span>ZVOLs</div>
			</a>
			
			<ul id="toc-ZVOLs-sublist" class="vector-toc-list">
				<li id="toc-RAIDZ_e_discos_físicos_com_Formatação_Avançada" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#RAIDZ_e_discos_f%C3%ADsicos_com_Formata%C3%A7%C3%A3o_Avan%C3%A7ada">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.4.1</span>RAIDZ e discos físicos com Formatação Avançada</div>
			</a>
			
			<ul id="toc-RAIDZ_e_discos_físicos_com_Formatação_Avançada-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Escalonador_de_E/S" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Escalonador_de_E/S">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.5</span>Escalonador de E/S</div>
			</a>
			
			<ul id="toc-Escalonador_de_E/S-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Solução_de_Problemas" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Solu%C3%A7%C3%A3o_de_Problemas">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">7</span>Solução de Problemas</div>
		</a>
		
			<button aria-controls="toc-Solução_de_Problemas-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Solução de Problemas subsection</span>
			</button>
		
		<ul id="toc-Solução_de_Problemas-sublist" class="vector-toc-list">
			<li id="toc-Criação_de_uma_zpool_falha" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Cria%C3%A7%C3%A3o_de_uma_zpool_falha">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.1</span>Criação de uma zpool falha</div>
			</a>
			
			<ul id="toc-Criação_de_uma_zpool_falha-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-ZFS_está_utilizando_muita_RAM" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#ZFS_est%C3%A1_utilizando_muita_RAM">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2</span>ZFS está utilizando muita RAM</div>
			</a>
			
			<ul id="toc-ZFS_está_utilizando_muita_RAM-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Não_contém_um_rótulo_EFI" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#N%C3%A3o_cont%C3%A9m_um_r%C3%B3tulo_EFI">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.3</span>Não contém um rótulo EFI</div>
			</a>
			
			<ul id="toc-Não_contém_um_rótulo_EFI-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Não_encontrou_hostid" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#N%C3%A3o_encontrou_hostid">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.4</span>Não encontrou hostid</div>
			</a>
			
			<ul id="toc-Não_encontrou_hostid-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Pool_não_encontrada_ao_iniciar_de_dispositivos_SAS/SCSI" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Pool_n%C3%A3o_encontrada_ao_iniciar_de_dispositivos_SAS/SCSI">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.5</span>Pool não encontrada ao iniciar de dispositivos SAS/SCSI</div>
			</a>
			
			<ul id="toc-Pool_não_encontrada_ao_iniciar_de_dispositivos_SAS/SCSI-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id='toc-Durante_a_inicialização,_a_pool_do_ZFS_não_monta_afirmando:_"pool_may_be_in_use_from_other_system"' class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href='#Durante_a_inicializa%C3%A7%C3%A3o,_a_pool_do_ZFS_n%C3%A3o_monta_afirmando:_"pool_may_be_in_use_from_other_system"'>
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.6</span>Durante a inicialização, a pool do ZFS não monta afirmando: "pool may be in use from other system"</div>
			</a>
			
			<ul id='toc-Durante_a_inicialização,_a_pool_do_ZFS_não_monta_afirmando:_"pool_may_be_in_use_from_other_system"-sublist' class="vector-toc-list">
				<li id="toc-Pool_não_exportada" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Pool_n%C3%A3o_exportada">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.6.1</span>Pool não exportada</div>
			</a>
			
			<ul id="toc-Pool_não_exportada-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-hostid_incorreta" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#hostid_incorreta">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.6.2</span>hostid incorreta</div>
			</a>
			
			<ul id="toc-hostid_incorreta-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Dispositivos_possuem_diferentes_alinhamentos_de_setor" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Dispositivos_possuem_diferentes_alinhamentos_de_setor">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.7</span>Dispositivos possuem diferentes alinhamentos de setor</div>
			</a>
			
			<ul id="toc-Dispositivos_possuem_diferentes_alinhamentos_de_setor-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Resilver_de_pool_parado/preso/reiniciando/lento?" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Resilver_de_pool_parado/preso/reiniciando/lento?">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.8</span>Resilver de pool parado/preso/reiniciando/lento?</div>
			</a>
			
			<ul id="toc-Resilver_de_pool_parado/preso/reiniciando/lento?-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Consertar_inicialização_lenta_causada_por_falha_na_importação_de_pools_indisponíveis_no_zpool.cache_do_initramfs" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Consertar_inicializa%C3%A7%C3%A3o_lenta_causada_por_falha_na_importa%C3%A7%C3%A3o_de_pools_indispon%C3%ADveis_no_zpool.cache_do_initramfs">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.9</span>Consertar inicialização lenta causada por falha na importação de pools indisponíveis no zpool.cache do initramfs</div>
			</a>
			
			<ul id="toc-Consertar_inicialização_lenta_causada_por_falha_na_importação_de_pools_indisponíveis_no_zpool.cache_do_initramfs-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Dicas_e_truques" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Dicas_e_truques">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">8</span>Dicas e truques</div>
		</a>
		
			<button aria-controls="toc-Dicas_e_truques-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Dicas e truques subsection</span>
			</button>
		
		<ul id="toc-Dicas_e_truques-sublist" class="vector-toc-list">
			<li id="toc-Embutir_os_pacotes_do_archzfs_na_archiso" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Embutir_os_pacotes_do_archzfs_na_archiso">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.1</span>Embutir os pacotes do archzfs na archiso</div>
			</a>
			
			<ul id="toc-Embutir_os_pacotes_do_archzfs_na_archiso-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Snapshots_automáticos" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Snapshots_autom%C3%A1ticos">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.2</span>Snapshots automáticos</div>
			</a>
			
			<ul id="toc-Snapshots_automáticos-sublist" class="vector-toc-list">
				<li id="toc-Serviço_de_snapshots_automáticos_do_ZFS_para_o_Linux" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Servi%C3%A7o_de_snapshots_autom%C3%A1ticos_do_ZFS_para_o_Linux">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.2.1</span>Serviço de snapshots automáticos do ZFS para o Linux</div>
			</a>
			
			<ul id="toc-Serviço_de_snapshots_automáticos_do_ZFS_para_o_Linux-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-zrepl" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#zrepl">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.2.2</span>zrepl</div>
			</a>
			
			<ul id="toc-zrepl-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Criando_um_compartilhamento" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Criando_um_compartilhamento">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3</span>Criando um compartilhamento</div>
			</a>
			
			<ul id="toc-Criando_um_compartilhamento-sublist" class="vector-toc-list">
				<li id="toc-NFS" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#NFS">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3.1</span>NFS</div>
			</a>
			
			<ul id="toc-NFS-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-SMB" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#SMB">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3.2</span>SMB</div>
			</a>
			
			<ul id="toc-SMB-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Criptografia_no_ZFS_utilizando_dm-crypt" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Criptografia_no_ZFS_utilizando_dm-crypt">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.4</span>Criptografia no ZFS utilizando dm-crypt</div>
			</a>
			
			<ul id="toc-Criptografia_no_ZFS_utilizando_dm-crypt-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Conserto_de_emergência_em_chroot_com_archzfs" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Conserto_de_emerg%C3%AAncia_em_chroot_com_archzfs">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.5</span>Conserto de emergência em chroot com archzfs</div>
			</a>
			
			<ul id="toc-Conserto_de_emergência_em_chroot_com_archzfs-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Montagem_com_bind" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Montagem_com_bind">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.6</span>Montagem com bind</div>
			</a>
			
			<ul id="toc-Montagem_com_bind-sublist" class="vector-toc-list">
				<li id="toc-fstab" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#fstab">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.6.1</span>fstab</div>
			</a>
			
			<ul id="toc-fstab-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Monitoração/envio_de_e-mails_em_eventos" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Monitora%C3%A7%C3%A3o/envio_de_e-mails_em_eventos">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.7</span>Monitoração/envio de e-mails em eventos</div>
			</a>
			
			<ul id="toc-Monitoração/envio_de_e-mails_em_eventos-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Utilizar_comandos_de_shell_antes_e_depois_de_snapshots" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Utilizar_comandos_de_shell_antes_e_depois_de_snapshots">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.8</span>Utilizar comandos de shell antes e depois de snapshots</div>
			</a>
			
			<ul id="toc-Utilizar_comandos_de_shell_antes_e_depois_de_snapshots-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Desbloquear_remotamente_root_ZFS_criptografado" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Desbloquear_remotamente_root_ZFS_criptografado">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.9</span>Desbloquear remotamente root ZFS criptografado</div>
			</a>
			
			<ul id="toc-Desbloquear_remotamente_root_ZFS_criptografado-sublist" class="vector-toc-list">
				<li id="toc-Mudando_a_porta_do_servidor_de_SSH" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Mudando_a_porta_do_servidor_de_SSH">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.9.1</span>Mudando a porta do servidor de SSH</div>
			</a>
			
			<ul id="toc-Mudando_a_porta_do_servidor_de_SSH-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Desbloquear_à_partir_de_uma_máquina_Windows_usando_PuTTY/Plink" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Desbloquear_%C3%A0_partir_de_uma_m%C3%A1quina_Windows_usando_PuTTY/Plink">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.9.2</span>Desbloquear à partir de uma máquina Windows usando PuTTY/Plink</div>
			</a>
			
			<ul id="toc-Desbloquear_à_partir_de_uma_máquina_Windows_usando_PuTTY/Plink-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Veja_também" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Veja_tamb%C3%A9m">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">9</span>Veja também</div>
		</a>
		
		<ul id="toc-Veja_também-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

					</div>
		</nav>
			</div>
		</div>
		<div class="mw-content-container">
			<main id="content" class="mw-body" role="main" style="margin: 0">
				<header class="mw-body-header vector-page-titlebar">
					<nav role="navigation" aria-label="Contents" class="vector-toc-landmark">
						
<div id="vector-page-titlebar-toc" class="vector-dropdown vector-page-titlebar-toc vector-button-flush-left">
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-dropdown-checkbox " aria-label="Toggle the table of contents">
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
	</label>
	<div class="vector-dropdown-content">


							<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
			</div>
		
	</div>
</div>

					</nav>
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">ZFS (Português)</span></h1>
							
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang">
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-dropdown-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 3 languages">
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-3" aria-hidden="true"><span class="vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive"></span>

<span class="vector-dropdown-label-text">3 languages</span>
	</label>
	<div class="vector-dropdown-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list">
				
				<li class="interlanguage-link interwiki-en mw-list-item"><a href="../en/ZFS.html" title="ZFS – English" lang="en" hreflang="en" class="interlanguage-link-target"><span>English</span></a></li>
<li class="interlanguage-link interwiki-ja mw-list-item"><a href="https://wiki.archlinux.jp/index.php/ZFS" title="ZFS – 日本語" lang="ja" hreflang="ja" class="interlanguage-link-target"><span>日本語</span></a></li>
<li class="interlanguage-link interwiki-zh-hans mw-list-item"><a href="https://wiki.archlinuxcn.org/wiki/ZFS" title="ZFS – 中文（简体）" lang="zh-Hans" hreflang="zh-Hans" class="interlanguage-link-target"><span>中文（简体）</span></a></li>
			</ul>
			
		</div>

	</div>
</div>
</header>
				<div class="vector-column-end">
					<div class="vector-sticky-pinned-container">
						<nav class="vector-page-tools-landmark" aria-label="Page tools">
							<div id="vector-page-tools-pinned-container" class="vector-pinned-container">
				
							</div>
		</nav>
						<nav class="vector-client-prefs-landmark" aria-label="Appearance">
						</nav>
					</div>
				</div>
				<div id="bodyContent" class="vector-body" aria-labelledby="firstHeading" data-mw-ve-target-container>
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From ArchWiki</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content">
<div class="mw-content-ltr mw-parser-output" lang="pt" dir="ltr">
<div class="archwiki-template-meta-related-articles">
<p>Artigos relacionados</p>
<ul>
<li><a href="../pt/File_systems.html" class="mw-redirect" title="Sistema de arquivos">Sistema de arquivos</a></li>
<li><a href="../en/ZFS/Virtual_disks.html" title="ZFS/Virtual disks">ZFS/Virtual disks</a></li>
<li><a href="../en/Install_Arch_Linux_on_ZFS.html" class="mw-redirect" title="Installing Arch Linux on ZFS">Installing Arch Linux on ZFS</a></li>
</ul>
</div>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Status de tradução:</strong> Esse artigo é uma tradução de <a href="../en/ZFS.html" title="ZFS">ZFS</a>. Data da última tradução: 2020-01-10. Você pode ajudar a sincronizar a tradução, se houver <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php?title=ZFS&amp;diff=0&amp;oldid=648658">alterações</a> na versão em inglês.</div>
<p><a href="https://en.wikipedia.org/wiki/pt:ZFS" class="extiw" title="wikipedia:pt:ZFS">ZFS</a> é um sistema de arquivos avançado criado pela <a href="https://en.wikipedia.org/wiki/pt:Sun_Microsystems" class="extiw" title="wikipedia:pt:Sun Microsystems">Sun Microsystems</a> (atualmente propriedade da Oracle) e lançado para OpenSolaris em novembro de 2005.
</p>
<p>Características do ZFS incluem: armazenamento em "pools" (gerenciamento integrado de volumes - zpool), <a href="https://en.wikipedia.org/wiki/pt:C%C3%B3pia_em_grava%C3%A7%C3%A3o" class="extiw" title="wikipedia:pt:Cópia em gravação">cópia em gravação</a>, <a href="https://en.wikipedia.org/wiki/pt:C%C3%B3pia_instant%C3%A2nea_de_volume" class="extiw" title="wikipedia:pt:Cópia instantânea de volume">snapshots</a>, verificação da integridade de dados e reparo automático (scrubbing - esfregar), <a href="https://en.wikipedia.org/wiki/pt:ZFS#RAID_de_software_usando_o_ZFS" class="extiw" title="wikipedia:pt:ZFS">RAID-Z</a>, tamanho de arquivo máximo de <a href="https://en.wikipedia.org/wiki/pt:Byte" class="extiw" title="wikipedia:pt:Byte">16 exabytes</a>, e um máximo de armazenamento de 256 quadrilhões de zettabytes sem limite de números de sistema de arquivos (datasets - conjuntos de dados) ou arquivos<a rel="nofollow" class="external autonumber" href="https://docs.oracle.com/cd/E19253-01/819-5461/zfsover-2/index.html">[1]</a>. (Conteúdo em inglês). O ZFS está licenciado sob a <a href="https://en.wikipedia.org/wiki/pt:CDDL" class="extiw" title="wikipedia:pt:CDDL">Common Development and Distribution License</a> (CDDL).
</p>
<p>Descrito como <a rel="nofollow" class="external text" href="https://web.archive.org/web/20060428092023/http://www.sun.com/2004-0914/feature/">"A última palavra em sistemas de arquivos"</a> (Conteúdo em inglês), o ZFS é estável, rápido, seguro e à prova de futuro. Tendo a licença como CDDL, e, portanto, incompatível com a GPL, não é possível que o ZFS seja distribuído junto ao Kernel Linux. Esta necessidade, no entanto, não impede que um módulo do Kernel nativo de Linux seja distribuído por terceiros, como é o caso com o <a rel="nofollow" class="external text" href="https://zfsonlinux.org/">zfsonlinux.org</a> (ZOL - ZFS no Linux/ZNL).
</p>
<p>ZNL é um projeto fundado pelo <a rel="nofollow" class="external text" href="https://www.llnl.gov/">Lawrence Livermore National Laboratory</a> para desenvolver um módulo nativo do Kernel do Linux para a necessidade de armazenamento maciço de dados em supercomputadores.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> 
<p>Devido à incompatibilidade potencialmente ilegais entre CDDL do ZFS e GPL do Kernel Linux, o desenvolvimento do ZFS não é suportado pelo Kernel, como mostrado nas seguintes páginas: (<a rel="nofollow" class="external autonumber" href="https://sfconservancy.org/blog/2016/feb/25/zfs-and-linux/">[2]</a>,<a href="https://en.wikipedia.org/wiki/Common_Development_and_Distribution_License#GPL_compatibility" class="extiw" title="wikipedia:Common Development and Distribution License">CDDL-GPL</a>,<a href="https://en.wikipedia.org/wiki/pt:ZFS#Linux" class="extiw" title="wikipedia:pt:ZFS">ZFS no Linux</a>).
</p>
<p>Como resultado:
</p>
<ul>
<li>O projeto ZFSonLinux deve acompanhar as versões do Kernel Linux. Após tornar um lançamento de uma versão estável do ZFSonLinux, os mantenedores do ZFS no Arch, fazem o lançamento junto à versão do Kernel.</li>
<li>Essa situação às vezes bloqueia o processo normal de atualização sem interrupção por dependências não satisfeitas, porque a nova versão do Kernel, proposta por atualização, não é suportada pelo ZFSonLinux</li>
</ul>
</div>
<meta property="mw:PageProp/toc">
<h2>
<span id="Instala.C3.A7.C3.A3o"></span><span class="mw-headline" id="Instalação">Instalação</span>
</h2>
<h3><span class="mw-headline" id="Geral">Geral</span></h3>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> A não ser que você utilize as versões <a href="../pt/Dynamic_Kernel_Module_Support.html" class="mw-redirect" title="DKMS (Português)">DKMS</a> dos pacotes, os módulos do Kernel ZFS e SPL estarão amarrados a uma versão específica do Kernel. Não será possível aplicar nenhuma atualização do Kernel até que pacotes atualizados sejam subidos para o AUR ou o repositório não-oficial <a href="../en/Unofficial_user_repositories.html#archzfs" title="Unofficial user repositories">archzfs</a>.</div>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Dica:</strong> Você pode fazer o <a href="../pt/Downgrading_packages.html" class="mw-redirect" title="Downgrade (Português)">downgrade</a> da sua versão do Linux para uma no repositório do <a href="../en/Unofficial_user_repositories.html#archzfs" title="Unofficial user repositories">archzfs</a> se sua versão for mais nova.</div>
<p>Instale do repositório não-oficial <a href="../en/Unofficial_user_repositories.html#archzfs" title="Unofficial user repositories">archzfs</a> ou, como alternativa, do <a href="../pt/Arch_User_Repository.html" title="Arch User Repository (Português)">AUR</a>:
</p>
<ul>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux/">zfs-linux</a></span><sup><small>AUR</small></sup>: lançamento <a rel="nofollow" class="external text" href="https://zfsonlinux.org/">estável</a>.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-git/">zfs-linux-git</a></span><sup><small>AUR</small></sup>: lançamento de <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/releases">desenvolvimento</a> (com suporte às novas versões de Kernel).</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-lts/">zfs-linux-lts</a></span><sup><small>AUR</small></sup>: lançamento estável do Kernel LTS.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-lts-git/">zfs-linux-lts-git</a></span><sup><small>AUR</small></sup><sup>[<a href="../en/ArchWiki:Requests.html#Broken_package_links" class="mw-redirect" title="ArchWiki:Requests">link quebrado</a>: package not found]</sup>: lançamento de desenvolvimento para o Kernel LTS.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-hardened/">zfs-linux-hardened</a></span><sup><small>AUR</small></sup>: lançamento estável do Kernel hardened.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-hardened-git/">zfs-linux-hardened-git</a></span><sup><small>AUR</small></sup><sup>[<a href="../en/ArchWiki:Requests.html#Broken_package_links" class="mw-redirect" title="ArchWiki:Requests">link quebrado</a>: package not found]</sup>: lançamento de desenvolvimento para o Kernel hardened.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-zen/">zfs-linux-zen</a></span><sup><small>AUR</small></sup>: lançamento estável do Kernel zen.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-zen-git/">zfs-linux-zen-git</a></span><sup><small>AUR</small></sup><sup>[<a href="../en/ArchWiki:Requests.html#Broken_package_links" class="mw-redirect" title="ArchWiki:Requests">link quebrado</a>: package not found]</sup>: lançamento de desenvolvimento para o Kernel zen.</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-dkms/">zfs-dkms</a></span><sup><small>AUR</small></sup>: lançamento com Dynamic Kernel Module Support (DKMS - Suporte a módulo de Kernel dinâmico).</li>
<li>
<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-dkms-git/">zfs-dkms-git</a></span><sup><small>AUR</small></sup>: lançamento de desenvolvimento com DKMS.</li>
</ul>
<p>Estas versões têm dependências do pacote <code>zfs-utils</code>.
</p>
<p>Teste a instalação rodando <code>zpool status</code> na linha de comando. Se aparecer um erro com "insmod", tente <code>depmod -a</code>.
</p>
<h3><span class="mw-headline" id="ZFS_na_raiz">ZFS na raiz</span></h3>
<p>Veja <a href="../en/Install_Arch_Linux_on_ZFS.html#Installation" title="Install Arch Linux on ZFS">Instalação</a>.
</p>
<h3><span class="mw-headline" id="DKMS">DKMS</span></h3>
<p>Usuários podem utilizar o <a href="../pt/Dynamic_Kernel_Module_Support.html" class="mw-redirect" title="DKMS (Português)">DKMS</a> para reconstruir o módulo do ZFS automaticamente com cada atualização do Kernel.
</p>
<p>Instale <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-dkms/">zfs-dkms</a></span><sup><small>AUR</small></sup> ou <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-dkms-git/">zfs-dkms-git</a></span><sup><small>AUR</small></sup> e aplique as instruções de pós-instalação dadas por estes pacotes.
</p>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Dica:</strong> Adicione uma entrada de <code>IgnorePkg</code> em <a href="../pt/Pacman.html#Configura%C3%A7%C3%A3o" title="Pacman (Português)">pacman.conf</a> para impedir que estes pacotes sejam atualizados em uma atualização regular.</div>
<h2><span class="mw-headline" id="Experimentos_com_ZFS">Experimentos com ZFS</span></h2>
<p>Usuários que tenham o desejo de realizar experimentos com ZFS em <i>dispositivos de blocos virtuais</i> (conhecidos no ZFS como VDEVs) que podem ser arquivos simples como <code>~/zfs0.img</code>, <code>~/zfs1.img</code>, <code>~/zfs2.img</code>, etc. sem a possibilidade de perda real de dados devem ver o artigo <a href="../en/ZFS/Virtual_disks.html" class="mw-redirect" title="Experimenting with ZFS">Experimenting with ZFS</a>. Tarefas comuns como construir um array (conjunto) em RAIDZ, propositalmente corromper dados e então recuperá-los, obter snapshots de datasets, etc. são cobertos nele.
</p>
<h2>
<span id="Configura.C3.A7.C3.A3o"></span><span class="mw-headline" id="Configuração">Configuração</span>
</h2>
<p>ZFS é considerado como um sitema de arquivos com "administração zero" pelos seus criadores; portanto, configurar o ZFS é um processo bem direto. A configuração é feita com 2 comandos: <code>zfs</code> e <code>zpool</code>.
</p>
<h3>
<span id="Inicializa.C3.A7.C3.A3o_autom.C3.A1tica"></span><span class="mw-headline" id="Inicialização_automática">Inicialização automática</span>
</h3>
<p>Atualmente, por padrão, o módulo do Kernel não é carregado durante a inicialização (veja mais detalhes em <a rel="nofollow" class="external free" href="https://github.com/zfsonlinux/zfs/issues/6083">https://github.com/zfsonlinux/zfs/issues/6083</a> - conteúdo em inglês). Para carregar automaticamente o <code>zfs</code>, veja <a href="../pt/Kernel_module.html#Carregamento_autom%C3%A1tico_de_m%C3%B3dulos_com_systemd" class="mw-redirect" title="Módulos de kernel">Módulos de kernel#Carregamento automático de módulos com systemd</a>.
</p>
<p>Para que o ZFS faça juz à "administração zero",o serviço <code>zfs-import-cache.service</code> deve ser habilitado para importar as pools e o <code>zfs-mount.service</code> deve ser habilitado para montar o sistema de arquivos disponível nas pools. Um benefício disto é que não é necessário montar os sistemas ZFS no <code>/etc/fstab</code>. O <code>zfs-import-cache.service</code> importa as pools lendo o arquivo <code>/etc/zfs/zpool.cache</code>.
</p>
<p>Para cada <a href="#Importando_por_id_uma_pool_criada">pool importada</a>, é desejável que o serviço <code>zfs-import-cache.service</code> que foi importado automaticamente, execute o seguinte comando:
</p>
<pre># zpool set cachefile=/etc/zfs/zpool.cache &lt;pool&gt;
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> À partir da versão 0.6.5.8 do ZNL, os arquivos das unidades de serviço do ZFS foram mudadas para que você explicitamente habilite quaisquer serviços do ZFS que você queira executar. Veja o conteúdo em inglês <a rel="nofollow" class="external text" href="https://github.com/archzfs/archzfs/issues/72">https://github.com/archzfs/archzfs/issues/72</a> para mais informações.</div>
<p>Habilite o serviço e o .target relevante para que as pools sejam automaticamente importadas durante a inicialização:
</p>
<pre># systemctl enable zfs-import-cache
# systemctl enable zfs-import.target
</pre>
<p>Para montar os sistemas de arquivos ZFS, você possui 2 opções:
</p>
<ul>
<li>Habilite o <a href="#Usando_zfs-mount.service">zfs-mount.service</a>
</li>
<li>Use o <a href="#Usando_zfs-mount-generator">zfs-mount-generator</a>
</li>
</ul>
<h4><span class="mw-headline" id="Usando_zfs-mount.service">Usando zfs-mount.service</span></h4>
<p>Para montar os sistemas de arquivos ZFS automaticamente durante o boot, você precisa habilitar os seguintes serviços e alvos.
</p>
<pre># systemctl enable zfs-mount
# systemctl enable zfs.target
</pre>
<h4><span class="mw-headline" id="Usando_zfs-mount-generator">Usando zfs-mount-generator</span></h4>
<p>Você também pode usar o <code>zfs-mount-generator</code> para criar unidades de montagem do systemd para seus sistemas de arquivos ZFS durante a inicialização. O systemd irá automaticamente montar os sistemas de arquivos baseados nas unidades de montagem sem a necessidade de usar <code>zfs-mount.service</code> para fazer isto. Para isto, você precisa:
</p>
<ol>
<li>Criar o diretório <code>/etc/zfs/zfs-list.cache</code>.</li>
<li>Habilitar o script do ZFS Event Daemon (ZED - servidor de evento do ZFS, chamado de ZEDLET) necessário para criar uma lista de sistemas de arquivos montáveis do ZFS. <pre># ln -s /usr/lib/zfs/zed.d/history_event-zfs-list-cacher.sh /etc/zfs/zed.d</pre>
</li>
<li>Habilitar e iniciar o ZFS Event Daemon. Este serviço é responsável por executar o script do passo anterior. <pre># systemctl enable zfs-zed.service<br># systemctl enable zfs.target<br># systemctl start zfs-zed.service</pre>
</li>
<li>Você precisa criar um arquivo vazio com o nome baseado no nome da sua pool em <code>/etc/zfs/zfs-list.cache</code>. O ZEDLET irá apenas atualizar a lista de sistema(s) de arquivos se o arquivo da pool já existir. <pre># touch /etc/zfs/zfs-list.cache/<i>nome-da-pool</i></pre>
</li>
<li>Verifique o conteúdo de <code>/etc/zfs/zfs-list.cache/<i>nome-da-pool</i></code>. Se estiver vazio, assegure-se que o <code>zfs-zed.service</code> está executando e só mude a propriedade <code>canmount</code> de quaisquer sistemas de arquivos ZFS executando: <pre>zfs set canmount=off zroot/fs1</pre> Esta mudança faz com que o ZFS crie um evento que é capturado pelo ZED, que, então, roda o ZEDLET para atualizar o arquivo em <code>/etc/zfs/zfs-list.cache</code>. Se o arquivo em <code>/etc/zfs/zfs-list.cache</code> for atualizado, você pode definir a propriedade <code>canmount</code> do sistema de arquivos de volta executando: <pre>zfs set canmount=on zroot/fs1</pre>
</li>
</ol>
<p>Você precisa acrescentar um arquivo em <code>/etc/zfs/zfs-list.cache</code> para cada pool ZFS no seu sistema. Assegure-se que as pools serão importadas habilitando <code>zfs-import-cache.service</code> e <code>zfs-import.target</code> conforme <a href="#Inicializa%C3%A7%C3%A3o_autom%C3%A1tica">explicado acima</a>.
</p>
<h2><span class="mw-headline" id="Pools_de_Armazenamento">Pools de Armazenamento</span></h2>
<p>Não é necessário particionar os dispositivos antes de criar o sistema de arquivos ZFS. É recomendado apontar o ZFS para um disco inteiro (ex: `/dev/sdx` em vez de `/dev/sdx1`), que irá <a rel="nofollow" class="external text" href="https://www.reddit.com/r/zfs/comments/667na0/zfs_on_raw_or_gpt/dgh0l9t/">automaticamente criar uma tabela de partições GPT</a> (conteúdo em inglês) e acrescentar uma partição reservada de 8 MB no final do disco para carregadores de inicialização legados. No entando, você pode especificar a partição ou um arquivo dentro do sistema de arquivos existente, se você deseja criar multiplos volumes com propriedades de redundância diferentes.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> Se algum ou todos os dispositivos foram usados em um conjunto de RAID por software, é primordial <a href="../en/RAID.html#Prepare_the_devices" class="mw-redirect" title="Mdadm">apagar quaisquer informações de configuração antigas de RAID</a>.</div>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> Para <a href="#Discos_com_formata%C3%A7%C3%A3o_avan%C3%A7ada">#Discos com formatação avançada</a> com tamanho de setor de 4KB, um <code>ashift</code> com valor 12 é recomendado para melhor desempenho. Discos com formatação avançada emulam um setor com tamanho de disco de 512 bytes para compatibilidade com sistemas legado. Uma vez que o pool foi criado, a única maneira de mudar a opção do <code>ashift</code> é recriar o pool. Usar um <code>ashift</code> de 12 também diminui a capacidade disponível. Veja <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/wiki/faq#performance-considerations">1.10 What’s going on with performance?</a>, <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/wiki/faq#advanced-format-disks">1.15 How does ZFS on Linux handle [Advanced</a>(Advanced) Format disks?], e <a rel="nofollow" class="external text" href="http://wiki.illumos.org/display/illumos/ZFS+and+Advanced+Format+disks">ZFS and Advanced Format disks</a>.</div>
<h3><span class="mw-headline" id="Identificando_discos">Identificando discos</span></h3>
<p><a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/wiki/faq#selecting-dev-names-when-creating-a-pool">ZFS no Linux</a> recomenda utilizar IDs do dispositivo quando for criar pools de armazenamento com menos de 10 dispositivos. Use <a href="../pt/Persistent_block_device_naming.html#by-id_e_by-path" class="mw-redirect" title="Nomeação persistente de dispositivo de bloco">Nomeação persistente de dispositivo de bloco#by-id e by-path</a> para identificar a lista de dispositivos que serão utilizados no pool ZFS.
</p>
<p>Os IDs dos discos serão similares ao seguinte:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ls -lh /dev/disk/by-id/</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">lrwxrwxrwx 1 root root  9 Aug 12 16:26 ata-ST3000DM001-9YN166_S1F0JKRR -&gt; ../../sdc
lrwxrwxrwx 1 root root  9 Aug 12 16:26 ata-ST3000DM001-9YN166_S1F0JTM1 -&gt; ../../sde
lrwxrwxrwx 1 root root  9 Aug 12 16:26 ata-ST3000DM001-9YN166_S1F0KBP8 -&gt; ../../sdd
lrwxrwxrwx 1 root root  9 Aug 12 16:26 ata-ST3000DM001-9YN166_S1F0KDGY -&gt; ../../sdb</pre>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> Se você criar zpools utilizando nomes dos dispositivos como <code>/dev/sda</code>, <code>/dev/sdb</code>, etc. o ZFS pode não ser capaz de detectar zpools intermitentemente na inicialização.</div>
<h4>
<span id="Utilizando_r.C3.B3tulos_GPT"></span><span class="mw-headline" id="Utilizando_rótulos_GPT">Utilizando rótulos GPT</span>
</h4>
<p>Rótulos de disco e UUIDs podem ser utilizados por montagens de ZFS usando partições <a href="../pt/Partitioning.html#Tabela_de_Parti%C3%A7%C3%A3o_GUID" class="mw-redirect" title="Particionamento">GPT</a>. Dispositivos ZFS possuem rótulos mas o Linux não é capaz de lê-los durante a inicialização. Ao contrário de partições <a href="../pt/Partitioning.html#Master_Boot_Record" class="mw-redirect" title="Particionamento">MBR</a>, partições GPT diretamente suportam tanto UUID quanto rótulos, independente do formato dentro da partição. Particionar ao invés de utilizar o disco todo para o ZFS oferece duas vantagens adicionais. O SO não precisa gerar números de partição falsos à partir de quaisquer dados que o ZFS possa ter escrito no setor de particionamento, e, se desejado, é possível provisionar excessivamente dispositivos SSD, e provisionar ligeiramente mais discos de eixo para assegurar que diferentes modelos com contagem de setores diferentes possam substituir espelhos no seu zpool. Isto permite muita organização e controle sobre o ZFS utilizando ferramentas e técnicas prontamente disponíveis com custo quase nulo.
</p>
<p>Utilize o <a href="../pt/Partitioning.html#Tabela_de_Parti%C3%A7%C3%A3o_GUID" class="mw-redirect" title="Particionamento">gdisk</a> para particionar todo ou apenas uma parte do disco como uma única partição. O gdisk não nomeia automaticamente as partições. Algumas razões para preferir rótulos ao invés de UUID são: rótulos são fáceis de controlar, podem indicar o propósito de cada disco, são mais curtos e mais simples de digitar. Estas são vantagens quando o servidor está inoperante e há pressão para restabelecimento. Rótulos de partições do GPT possuem amplo espaço disponível e podem suportar a maioria dos caracteres internacionais (<a href="https://en.wikipedia.org/wiki/pt:Tabela_de_Parti%C3%A7%C3%A3o_GUID#Entradas_de_parti.C3.A7.C3.A3o_.28LBA_2.E2.80.9333.29" class="extiw" title="wikipedia:pt:Tabela de Partição GUID">Entradas de Partição</a>) permitindo que grandes pools de dados sejam rotulados de uma maneira organizada.
</p>
<p>Discos particionados com GPT possuem rótulos e UUIDs que parecem com o seguinte:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ls -l /dev/disk/by-partlabel</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">lrwxrwxrwx 1 root root 10 Apr 30 01:44 zfsdata1 -&gt; ../../sdd1
lrwxrwxrwx 1 root root 10 Apr 30 01:44 zfsdata2 -&gt; ../../sdc1
lrwxrwxrwx 1 root root 10 Apr 30 01:59 zfsl2arc -&gt; ../../sda1</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ls -l /dev/disk/by-partuuid</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">lrwxrwxrwx 1 root root 10 Apr 30 01:44 148c462c-7819-431a-9aba-5bf42bb5a34e -&gt; ../../sdd1
lrwxrwxrwx 1 root root 10 Apr 30 01:59 4f95da30-b2fb-412b-9090-fc349993df56 -&gt; ../../sda1
lrwxrwxrwx 1 root root 10 Apr 30 01:44 e5ccef58-5adf-4094-81a7-3bac846a885f -&gt; ../../sdc1</pre>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Dica:</strong>  Para minimizar digitar e erros ao copiar/colar, defina uma variável local com o PARTUUID de destino: <code>$ UUID=$(lsblk --noheadings --output PARTUUID /dev/sd<i>XY</i>)</code> </div>
<h3><span class="mw-headline" id="Criando_pools_ZFS">Criando pools ZFS</span></h3>
<p>Para criar uma pool com ZFS:
</p>
<pre># zpool create -f -m &lt;montagem&gt; &lt;pool&gt; [raidz(2|3)|mirror] &lt;ids&gt;
</pre>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Dica:</strong> É útil ler primeiro <a href="#Discos_com_formata%C3%A7%C3%A3o_avan%C3%A7ada">#Discos com formatação avançada</a> para definir o valor correto de <code>ashift</code> durante a criação da pool</div>
<ul><li>
<b>create</b>: subcomando para criar a pool.</li></ul>
<ul><li>
<b>-f</b>: força a criação da pool. Isto serve para ignorar o "EFI label error" (erro de rótulo EFI). Veja <a href="#N%C3%A3o_cont%C3%A9m_um_r%C3%B3tulo_EFI">#Não contém um rótulo EFI</a>.</li></ul>
<ul><li>
<b>-m</b>: O ponto de montagem da pool. Se não for especificado, então a pool será montada diretamente em <code>/&lt;<i>pool</i>&gt;</code>.</li></ul>
<ul><li>
<b>pool</b>: É o nome da pool.</li></ul>
<ul><li>
<b>raidz(2|3)|mirror</b>: Este é o tipo de dispositivo virtual que será criado à partir do conjunto de dispositivos de armazenamento, raidz possui um único disco de paridade, raidz2, 2 discos e raidz3 possui 3 discos de paridade, similares ao RAID5 e RAID6. Também há <b>mirror</b>, que é similar ao RAID1 ou RAID10, mas não é restrito à apenas 2 dispositivos. Se não especificado, cada dispositivo será acrescido como vdev, o que é similar ao RAID0. Após a criação, um dispositivo pode ser adicionado a cada vdev de dispositivo para transformar em um espelho (mirror), o que pode ser útil para migrar dados.</li></ul>
<ul><li>
<b>ids</b>: O <a href="../pt/Persistent_block_device_naming.html#by-id_e_by-path" class="mw-redirect" title="Nomeação persistente de dispositivo de bloco">ID</a> dos dispositivos ou partições para incluir na pool.</li></ul>
<p>Criar pool com um único vdev em raidz:
</p>
<pre># zpool create -f -m /mnt/dados bigdata \
        raidz \
            ata-ST3000DM001-9YN166_S1F0KDGY \
            ata-ST3000DM001-9YN166_S1F0JKRR \
            ata-ST3000DM001-9YN166_S1F0KBP8 \
            ata-ST3000DM001-9YN166_S1F0JTM1
</pre>
<p>Criar pool com dois vdevs em espelhados:
</p>
<pre># zpool create -f -m /mnt/dados bigdata \
        mirror \
            ata-ST3000DM001-9YN166_S1F0KDGY \
            ata-ST3000DM001-9YN166_S1F0JKRR \
        mirror \
            ata-ST3000DM001-9YN166_S1F0KBP8 \
            ata-ST3000DM001-9YN166_S1F0JTM1
</pre>
<h4>
<span id="Discos_com_formata.C3.A7.C3.A3o_avan.C3.A7ada"></span><span class="mw-headline" id="Discos_com_formatação_avançada">Discos com formatação avançada</span>
</h4>
<p>Durante a criação da pool, <b>ashift=12</b> deve sempre ser utilizado, exceto com SSDs que possuem setores com 8km onde <b>ashift=13</b> é o correto. Um disco com vdev de tamanho 512 bytes usando setores de 4k não irá experienciar problemas de desempenho, mas um disco de 4k usando 512 irá. Já que <b>ashift</b> não pode ser mudado após a criação da pool, até uma pool com apenas discos de 512 bytes deve usar 4k pois pode ser necessário a substituição destes discos com outros de 4k, ou ainda a pool pode ser expandida acrescentando um vdev composto por discos de 4k. Como a detecção correta de discos de 4k não é confiável <code>-o ashift=12</code> deve sempre ser utilizado durante a criação da pool, veja o conteúdo em inglês <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/wiki/faq#advanced-format-disks">ZFS on Linux FAQ</a> para mais detalhes.
</p>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Dica:</strong> Use <span class="plainlinks archwiki-template-man" title="$ man 8 blockdev"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/blockdev.8">blockdev(8)</a></span> (parte do <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=util-linux">util-linux</a></span>) como root para mostrar o tamanho do setor informado pelo ioctls do dispositivo: <code>blockdev --getpbsz /dev/sd<i>XY</i></code>.</div>
<p>Crie uma pool com ashift=12 e um único vdev em raidz:
</p>
<pre># zpool create -f -o ashift=12 -m /mnt/dados bigdata \
               raidz \
                  ata-ST3000DM001-9YN166_S1F0KDGY \
                  ata-ST3000DM001-9YN166_S1F0JKRR \
                  ata-ST3000DM001-9YN166_S1F0KBP8 \
                  ata-ST3000DM001-9YN166_S1F0JTM1
</pre>
<h4>
<span id="Cria.C3.A7.C3.A3o_de_pool_compat.C3.ADvel_com_GRUB"></span><span class="mw-headline" id="Criação_de_pool_compatível_com_GRUB">Criação de pool compatível com GRUB</span>
</h4>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> Esta seção frequentemente fica desatualizada com atualizações de GRUB e ZFS. Consulte as páginas de manual para informação mais atual.</div>
<p>Por padrão, <i>zpool create</i> permite todas as opções em uma pool. Se /boot reside em um ZFS quando usando o <a href="../pt/GRUB.html" title="GRUB (Português)">GRUB</a>, você deve habilitar apenas as opções suportadas pelo GRUB, caso não faça isso, o GRUB não conseguirá ler a pool. O GRUB 2.02 suporta as opções de leitura e gravação <code>lz4_compress</code>, <code>hole_birth</code>, <code>embedded_data</code>, <code>extensible_dataset</code>, e <code>large_blocks</code>, isto não condiz com todas as opções no ZFSonLinux 0.8.0, e deve ter as opções não adequadas desabilitadas. Pode-se inserir explicitamente o nome das opções habilitadas com o argumento <code>-d</code> para o comando <code>zpool create</code>, que desabilita todas as opções por padrão.
</p>
<p>Você pode criar a pool com apenas as opções permitidas habilitadas:
</p>
<pre># zpool create -d -o feature@allocation_classes=enabled \
                  -o feature@async_destroy=enabled      \
                  -o feature@bookmarks=enabled          \
                  -o feature@embedded_data=enabled      \
                  -o feature@empty_bpobj=enabled        \
                  -o feature@enabled_txg=enabled        \
                  -o feature@extensible_dataset=enabled \
                  -o feature@filesystem_limits=enabled  \
                  -o feature@hole_birth=enabled         \
                  -o feature@large_blocks=enabled       \
                  -o feature@lz4_compress=enabled       \
                  -o feature@project_quota=enabled      \
                  -o feature@resilver_defer=enabled     \
                  -o feature@spacemap_histogram=enabled \
                  -o feature@spacemap_v2=enabled        \
                  -o feature@userobj_accounting=enabled \
                  -o feature@zpool_checkpoint=enabled   \
                  $<i>NOME_DA_POOL</i> $VDEVS
</pre>
<h3><span class="mw-headline" id="Verificando_status_da_pool">Verificando status da pool</span></h3>
<p>Se o comando for executado com sucesso, não será mostrada saída. Usando o comando <a href="../pt/File_systems.html#Montar_um_sistema_de_arquivos" class="mw-redirect" title="Sistemas de arquivos">mount</a> mostrará que a pool está montada. Usando <code>zpool status</code> mostrará que a pool foi criada:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># zpool status -v</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">  pool: bigdata
 state: ONLINE
  scan: none requested
config:

        NAME                                       STATE     READ WRITE CKSUM
        bigdata                                    ONLINE       0     0     0
          -0                                       ONLINE       0     0     0
            ata-ST3000DM001-9YN166_S1F0KDGY-part1  ONLINE       0     0     0
            ata-ST3000DM001-9YN166_S1F0JKRR-part1  ONLINE       0     0     0
            ata-ST3000DM001-9YN166_S1F0KBP8-part1  ONLINE       0     0     0
            ata-ST3000DM001-9YN166_S1F0JTM1-part1  ONLINE       0     0     0

errors: No known data errors
</pre>
<p>Nesse momento, seria bom reiniciar a máquina para assegurar-se que a pool ZFS será montada durante a inicialização. É melhor lidar com todos os erros antes de transferir dados.
</p>
<h3><span class="mw-headline" id="Importando_por_id_uma_pool_criada">Importando por id uma pool criada</span></h3>
<p>Eventualmente, uma pool pode falhar ao auto montar, então você precisará importar para trazer a pool de volta. Cuidado para evitar usar a solução óbvia.
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> Não rode <code>zpool import <i>pool</i></code>! Isto irá importar seus pools utilizando <code>/dev/sd?</code> que irá causar problemas a próxima vez que rearranjar seus drives. Que pode ser algo simples como reiniciar com um USB conectado na máquina.</div>
<p>Adapte algum dos comandos seguintes para importar sua pool para que as importações dela retenham a persistência com que foram criadas.
</p>
<pre># zpool import -d /dev/disk/by-id         bigdata
# zpool import -d /dev/disk/by-partlabel  bigdata
# zpool import -d /dev/disk/by-partuuid   bigdata
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> Use a opção <code>-l</code> ao importar a pool que contenha <a href="#Criptografia_nativa">chaves de conjuntos de dados criptografadas</a>:
<pre># zpool import -l -d /dev/disk/by-id bigdata
</pre>
</div>
<p>Finalmente, verifique o estado da pool:
</p>
<pre># zpool status -v bigdata
</pre>
<h3><span class="mw-headline" id="Destruir_uma_pool_de_armazenamento">Destruir uma pool de armazenamento</span></h3>
<p>ZFS torna fácil destruir uma pool de armazenamento montada, removendo todos os metadados sobre o dispositivo ZFS.
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> Este comando destrói <b>qualquer dado</b> contido no pool e/ou dataset.</div>
<p>Para destruir a pool:
</p>
<pre># zpool destroy &lt;pool&gt;
</pre>
<p>Para destruir o dataset:
</p>
<pre># zfs destroy &lt;pool&gt;/&lt;dataset&gt;
</pre>
<p>E agora, ao verificar o status:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># zpool status</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">no pools available
</pre>
<h3><span class="mw-headline" id="Exportar_uma_pool_de_armazenamento">Exportar uma pool de armazenamento</span></h3>
<p>Se uma pool de armazenamento precisar ser utilizada em outro sistema, primeiro necessitará ser importada. Também faz-se necessário exportar uma pool se ela foi importada à partir da archiso pois o <i>hostid</i> será diferente entre a ISO e o sistema inicializado. O comando zpool se recusará a importar quaisquer pools de armazenamento que não foram exportadas. É possível forçar a importação com a opção <code>-f</code> mas esta prática é considerada ruim.
</p>
<p>Quaisquer tentativas de importar uma pool de armazenamento não exportadas resultará em um erro ao iniciar a pool de armazenamento informando estar sendo utilizada em outro sistema. Este erro pode ser produzido durante a inicialização, abruptamente abandonando o sistema na console <i>busybox</i>, necessitando da archiso para fazer o conserto, seja via exportação da pool, seja acrescentando <code>zfs_force=1</code> aos parâmetros de inicialização do Kernel (o que não é ideal). Veja mais em <a href='#Durante_a_inicializa%C3%A7%C3%A3o,_a_pool_do_ZFS_n%C3%A3o_monta_afirmando:_"pool_may_be_in_use_from_other_system"'>#Durante a inicialização, a pool do ZFS não monta afirmando: "pool may be in use from other system"</a>.
</p>
<p>Para exportar uma pool:
</p>
<pre># zpool export &lt;pool&gt;
</pre>
<h3><span class="mw-headline" id="Estendendo_uma_pool_existente">Estendendo uma pool existente</span></h3>
<p>Um dispositivo (uma partição ou um disco) pode ser acrescentado a uma zpool existente:
</p>
<pre># zpool add &lt;pool&gt; &lt;id-do-dispositivo&gt;
</pre>
<p>Para importar uma pool que consiste de múltiplos dispositivos:
</p>
<pre># zpool import -d &lt;id-do-dispositivo-1&gt; -d &lt;id-do-dispositivo-2&gt; &lt;pool&gt;
</pre>
<p>Ou simplesmente:
</p>
<pre># zpool import -d /dev/disk-by-id/ &lt;pool&gt;
</pre>
<h3><span class="mw-headline" id="Renomear_uma_pool">Renomear uma pool</span></h3>
<p>Renomear uma pool que já foi criada é feito em 2 passos:
</p>
<pre># zpool export nome-antigo
# zpool import nome-antigo nome-novo
</pre>
<h3><span class="mw-headline" id="Definir_um_ponto_de_montagem_diferente">Definir um ponto de montagem diferente</span></h3>
<p>O ponto de montagem para uma determinada zpool pode ser movido conforme desejado com um comando:
</p>
<pre># zfs set mountpoint=/foo/bar nome-da-pool
</pre>
<h2><span class="mw-headline" id="Criando_datasets">Criando datasets</span></h2>
<p>Usuários possuem a opção de criar um dataset sob uma zpool, diferente de manualmente criar diretórios sob a zpool. Datasets permitem um nível maior de controle (por exemplo quotas), além de snapshots. Para conseguir criar e montar um dataset, um diretório homônimo não deve existir na zpool. Para criar um dataset, use:
</p>
<pre># zfs create &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<p>Então é possível aplicar atributos específicos do ZFS ao dataset. Por exemplo, limite de quota para um diretório específico dentro de um dataset:
</p>
<pre># zfs set quota=20G &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;/&lt;diretório&gt;
</pre>
<p>Para ver todos os comandos disponíveis no ZFS, veja <span class="plainlinks archwiki-template-man" title="$ man 8 zfs">zfs(8)</span> ou <span class="plainlinks archwiki-template-man" title="$ man 8 zpool">zpool(8)</span>.
</p>
<h3><span class="mw-headline" id="Criptografia_nativa">Criptografia nativa</span></h3>
<p>ZFS oferece as seguintes opções suportadas de Criptografia: <code>aes-128-ccm</code>, <code>aes-192-ccm</code>, <code>aes-256-ccm</code>, <code>aes-128-gcm</code>, <code>aes-192-gcm</code> e <code>aes-256-gcm</code>. Quando a Criptografia é definida como <code>on</code>, <code>aes-256-gcm</code> será usada.
</p>
<p>Os seguintes formatos de chave são suportados: <code>passphrase</code>, <code>raw</code>, <code>hex</code>.
</p>
<p>É possível também especificar as iterações padrões do PBKDF2 quando usando <code>passphrase</code> com <code>-o pbkdf2iters &lt;n&gt;</code>, embora isto possa aumentar o tempo até terminar a descriptografia.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> 
<ul>
<li>Criptografia nativa no ZFS tornou-se disponível à partir da versão estável 0.8.0 ou mais nova. Anteriormente estavam disponíveis apenas em versões de desenvolvimento fornecidas por pacotes como <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-linux-git/">zfs-linux-git</a></span><sup><small>AUR</small></sup>, <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-dkms-git/">zfs-dkms-git</a></span><sup><small>AUR</small></sup> ou outras versões de desenvolvimento. Usuários que estavam utilizando as versões de desenvolvimento devido à criptografia podem agora trocar pela versão estável se assim desejarem.</li>
<li>A suite padrão de criptografia foi mudada de <code>aes-256-ccm</code> para <code>aes-256-gcm</code> na versão 0.8.4.</li>
<li>Para importar uma pool com chaves, é necessário especificar a opção <code>-l</code>, sem esta opção, datasets criptografados ficarão indisponíveis até que as chaves sejam carregadas. Veja<a href="#Importando_por_id_uma_pool_criada">#Importando por id uma pool criada</a>.</li>
</ul>
</div>
<p>Para criar um dataset, incluíndo criptografia por senha, use:
</p>
<pre># zfs create -o encryption=on -o keyformat=passphrase &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<p>Para utilizar chave ao invés de senha, use:
</p>
<pre># dd if=/dev/random of=<i>/caminho/para/chave</i> bs=1 count=32
# zfs create -o encryption=on -o keyformat=raw -o keylocation=file://of=<i>/caminho/para/chave</i> &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<p>Para verificar o local da chave:
</p>
<pre># zfs get keylocation &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<p>Para mudar o local da chave:
</p>
<pre># zfs set keylocation=file://<i>/caminho/para/chave</i> &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<p>Você também pode manualmente carregar as chaves utilizando um dos seguintes comandos:
</p>
<pre># zfs load-key &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt; # Carrega uma chave para um dataset específico
# zfs load-key -a                                # Carrega todas as chaves
# zfs load-key -r zpool/dataset                  # Carrega todas as chaves em um dataset
</pre>
<p>Para montar um dataset criptografado criado:
</p>
<pre># zfs mount &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<h4>
<span id="Desbloquear_durante_a_inicializa.C3.A7.C3.A3o"></span><span class="mw-headline" id="Desbloquear_durante_a_inicialização">Desbloquear durante a inicialização</span>
</h4>
<p>É possível automaticamente desbloquear um dataset de uma pool durante a inicialização usando uma unidade do <a href="../pt/Systemd.html" title="Systemd (Português)">systemd</a>. Por exemplo, criar o seguinte serviço para desbloquear qualquer dataset específico.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/zfs-load-key@.service</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Carregar chaves de criptografia %I
Before=systemd-user-sessions.service
After=zfs-import.target

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/bin/bash -c 'until (systemd-ask-password "Senha criptografada do ZFS para %I" --no-tty | zfs load-key %I); do echo "Tente novamente!"; done'

[Install]
WantedBy=zfs-mount.service</pre>
<p><a href="../pt/Systemd.html#Usando_units" title="Systemd (Português)">Habilite e inicie</a> o serviço para cada dataset criptografado, e.g. <code>systemctl enable zfs-load-key@pool0-dataset0</code> como o usuário root. Note o uso do <code>-</code>, que é um <code>/</code> escapado nas definições de unidade do systemd. Veja <code>systemd-escape(1)</code> para mais informações.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> O <code>Before=systemd-user-sessions.service</code> garante que o systemd-ask-password seja invocado antes que os dispositivos locais de E/S sejam entregues para o <a href="../pt/Desktop_environment.html" class="mw-redirect" title="Ambiente de desktop">ambiente de desktop</a>.</div>
<p>Uma alternativa é carregar todas as chaves possíveis:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/zfs-load-key.service</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Carregar chaves de criptografia
DefaultDependencies=no
After=zfs-import.target
Before=zfs-mount.service

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/bin/zfs load-key -a

[Install]
WantedBy=zfs-mount.service</pre>
<p><a href="../pt/Systemd.html#Usando_units" title="Systemd (Português)">Habilite e inicie</a> <code>zfs-load-key.service</code>.
</p>
<h3><span class="mw-headline" id="Volume_de_swap">Volume de swap</span></h3>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> Em sistemas com pressão de memória extremamente alto, usar um zvol como swap pode resultar em em travamento, independente da quantidade de swap disponível. Este problema está atualmente sendo investigado <a rel="nofollow" class="external free" href="https://github.com/zfsonlinux/zfs/issues/7734">https://github.com/zfsonlinux/zfs/issues/7734</a>
</div>
<p>ZFS não permite o uso de arquivos de swap, mas usuários podem utilizar um volume de ZFS (ZVOL) como swap. É importante definir o tamanho de bloco do ZVOL para ser o mesmo do tamanho de página do sistema, que pode ser obtida com o comando <code>getconf PAGESIZE</code> (o padrão em x86_64 é 4KiB). Outra opção útil para manter o sistema rodando bem em situações de memória baixa é não fazer o cache dos dados do ZVOL.
</p>
<p>Crie um volume ZFS de 8 GiB:
</p>
<pre># zfs create -V 8G -b $(getconf PAGESIZE) \
              -o logbias=throughput -o sync=always\
              -o primarycache=metadata \
              -o com.sun:auto-snapshot=false &lt;pool&gt;/swap
</pre>
<p>Prepare-o como partição de swap:
</p>
<pre># mkswap -f /dev/zvol/&lt;pool&gt;/swap
# swapon /dev/zvol/&lt;pool&gt;/swap
</pre>
<p>Para tornar permanente, edite o <code>/etc/fstab</code>. ZVOLs suportam "discard", que potencialmente pode ajudar o alocador de blocos do ZFS e reduzir a fragmentação para todos os outros datasets quando/se o swap não estiver cheio.
</p>
<p>Acrescente uma linha no <code>/etc/fstab</code>:
</p>
<pre>/dev/zvol/&lt;pool&gt;/swap none swap discard 0 0
</pre>
<h3><span class="mw-headline" id="Listas_de_Controle_de_Acesso">Listas de Controle de Acesso</span></h3>
<p>Para utilizar <a href="../pt/Access_Control_Lists.html" class="mw-redirect" title="Listas de Controle de Acesso">Listas de Controle de Acesso</a> (ACL) em um dataset:
</p>
<pre># zfs set acltype=posixacl &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
# zfs set xattr=sa         &lt;<i>nome-da-zpool</i>&gt;/&lt;<i>nome-do-dataset</i>&gt;
</pre>
<p>Definir <code>xattr</code> é recomendado por questões de desempenho, como é possível ver no conteúdo em inglês <a rel="nofollow" class="external autonumber" href="https://github.com/zfsonlinux/zfs/issues/170#issuecomment-27348094">[3]</a>.
</p>
<p>Pode ser preferível habilitar o ACL na zpool pois os datasets irão herdar os parâmetros de ACL. Configurar <code>aclinherit=passthrough</code> Pode ser desejado pois o modo padrão é <code>restricted</code>, vide <a rel="nofollow" class="external autonumber" href="https://docs.oracle.com/cd/E19120-01/open.solaris/817-2271/gbaaz/index.html">[4]</a> (conteúdo em inglês):
</p>
<pre># zfs set aclinherit=passthrough &lt;<i>nome-da-zpool</i>&gt;
# zfs set acltype=posixacl       &lt;<i>nome-da-zpool</i>&gt;
# zfs set xattr=sa               &lt;<i>nome-da-zpool</i>&gt;
</pre>
<h3><span class="mw-headline" id="Bancos_de_dados">Bancos de dados</span></h3>
<p>ZFS, diferente da maioria dos outros sistemas de arquivos, tem u, tamanho de registro variável, ou o que é comumente chamado de tamanho de bloco. Por padrão, o tamanho de registro "recordsize" no ZFS é 128KiB, o que significa que irá alocar blocos dinamicamente de qualquer tamanho entre 512B e 128KiB, dependendo do tamanho do arquivo sendo escrito. Isto frequentemente pode ajudar com fragmentation e acesso a arquivos, com o custo que o ZFS teria ao alocar novos blocos de 128KiB cada vez que apenas alguns bytes são escritos.
</p>
<p>A maioria dos SGBDRs trabalham com blocos com tamanho de 8KiB por padrão. Apesar do tamanho de bloco ser regulável para <a href="../en/MySQL.html" title="MySQL">MySQL/MariaDB</a>, <a href="../en/PostgreSQL.html" title="PostgreSQL">PostgreSQL</a>, e Oracle database, todos os 3 usam o tamanho de bloco de 8KiB <i>por padrão</i>. Tanto para preocupações com desempenho e manter diferença mínima em snapshots (em questão de backups, é útil), geralmente é desejável realizar configurações no ZFS para acomodar os banco de dados utilizando comandos como:
</p>
<pre># zfs set recordsize=8K &lt;pool&gt;/postgres
</pre>
<p>Estes SGBDRs também tendem a implementar o próprio algoritmo de cache, geralmente similar ao próprio ARC do ZFS. Para economizar memória, é melhor simplemsnte desabilitar o cache do ZFS para o arquivo de banco de dados e deixar com que o banco faça o próprio gerenciamento:
</p>
<pre># zfs set primarycache=metadata &lt;pool&gt;/postgres
</pre>
<p>Se sua pool não possui dispositivos de log, o ZFS reserva espaço dos discos de dados das pools para seu log (ZIL). O ZFS utiliza isso para recuperação em casos de "crash", mas bancos de dados geralmente sincronizam seus arquivos de dados para o sistema de arquivos dentro das confirmações de transações de qualquer forma. O resultado final é que o ZFS fará a gravação dos dados <b>duas vezes</b>, isto pode impactar severamente o desempenho. Você pode gerenciar para que o ZFS não use o ZIL, neste caso, os dados serão gravados no sistema de arquivos uma vez. Configurando isto para sistemas de arquivos não destinados à bancos de dados ou para pools com dispositivos com log configurados podem impactar <i>negativamente</i> o desempenho, então cuidado:
</p>
<pre># zfs set logbias=throughput &lt;pool&gt;/postgres
</pre>
<p>Isto também pode ser feito durante a criação do sistema de arquvios, por exemplo:
</p>
<pre># zfs create -o recordsize=8K \
             -o primarycache=metadata \
             -o mountpoint=/var/lib/postgres \
             -o logbias=throughput \
              &lt;pool&gt;/postgres
</pre>
<p>Por favor perceba: estes tipos de parâmetros de refinamento são ideais para aplicações especializadas como sistemas de bancos de dados relacionais. Você pode prejudicar o desempenho do ZFS ao configurar um sistema de arquivos de propósito generalizado como o seu diretório /home.
</p>
<h3>
<span id=".2Ftmp"></span><span class="mw-headline" id="/tmp">/tmp</span>
</h3>
<p>Se você quiser usar o ZFS para armazenar seu diretório /tmp, o que pode ser útil para armazenar conjuntos de arquivos arbitrariamente grandes ou simplesmente manter sua RAM livre de dados, geralmente você pode melhorar o desempenho de certas aplicações que escrevem no /tmp desabilitando a sincronização do sistema de arquivos. Isto faz com que o ZFS ignore as requisições de sincronização das aplicações (e.g. com <code>fsync</code> ou <code>O_SYNC</code>) e retorne imediatamente.
Embora isso tenha sérias conseqüências de consistência de dados no lado de aplicações (nunca desative a sincronização para um banco de dados!), É menos provável que os arquivos em /tmp sejam importantes e afetados. Observe que isso <i>não</i> afeta a integridade do ZFS, apenas a possibilidade de que os dados esperados por um aplicativo no disco possam não ter sido gravados após um "crash".
</p>
<pre># zfs set sync=disabled &lt;pool&gt;/tmp
</pre>
<p>Além disso, por motivos de segurança. você pode querer desabilitar <b>setuid</b> e <b>devices</b> no sistema de arquivos /tmp, o que impede alguns tipos de ataques de escalação de privilégios ou o uso de nós de dispositivos:
</p>
<pre># zfs set setuid=off  &lt;pool&gt;/tmp
# zfs set devices=off &lt;pool&gt;/tmp
</pre>
<p>Combinar todos eles em um comando de criação é feito da seguinte forma:
</p>
<pre># zfs create -o setuid=off -o devices=off -o sync=disabled -o mountpoint=/tmp &lt;pool&gt;/tmp
</pre>
<p>Por favor note, também. que se você deseja /tmp no ZFS, você precisará mascarar (desabilitar) o /tmp baseado em tmpfs automático do <a href="../pt/Systemd.html" title="Systemd (Português)">systemd</a>, se não, o ZFS não será capaz de montar seu dataset durante a inicialização ou durante a etapa de importação:
</p>
<pre># systemctl mask tmp.mount
</pre>
<h2><span class="mw-headline" id="Refinamento">Refinamento</span></h2>
<h3><span class="mw-headline" id="Geral_2">Geral</span></h3>
<p>Pools e datasets do ZFS podem ter ainda mais ajustes e refinamentos (tunings) utilizando parâmetros.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> Todas as propriedades configuráveis, com exceção de quotas e reservas, herdam seu valor do dataset pai.</div>
<p>Para obter o status atual com os parâmetros da pool:
</p>
<pre># zfs get all &lt;pool&gt;
</pre>
<p>Para obter o status atual com os parâmetros do dataset:
</p>
<pre># zfs get all &lt;pool&gt;/&lt;dataset&gt;
</pre>
<p>Para desabilitar o tempo de acesso (atime), que é habilitado por padrão:
</p>
<pre># zfs set atime=off &lt;pool&gt;
</pre>
<p>Para desabilitar o tempo de acesso (atime) em um dataset específico:
</p>
<pre># zfs set atime=off &lt;pool&gt;/&lt;dataset&gt;
</pre>
<p>Uma alternativa a desabilitar o atime completamente, o <code>relatime</code> está disponível. Isto traz a semântica padrão do ext4/XFS ao ZFS, na qual o tempo de acesso somente é atualizado se o tempo de modificação ou tempo de criação é modificado, ou se o tempo existente de acesso não foi atualizado dentro das últimas 24 horas. É uma mistura entre <code>atime=off</code> e <code>atime=on</code>. Esta propriedade <i>só</i> tem efeito se <code>atime</code> estiver <code>on</code>.
</p>
<pre># zfs set atime=on    &lt;pool&gt;
# zfs set relatime=on &lt;pool&gt;
</pre>
<p>Compression é apenas compressão transparente de dados. ZFS suporta poucos algoritmos, atualmente lz4 é o padrão, <i>gzip</i> também está disponível para dados raramente escrítos e ainda assim altamente compressível;  consulte mais detalhes na <a rel="nofollow" class="external text" href="http://open-zfs.org/wiki/Performance_tuning#Compression">Wiki do OpenZFS</a> (conteúdo em inglês) para mais detalhes.
</p>
<p>Para habilitar compressão:
</p>
<pre># zfs set compression=on &lt;pool&gt;
</pre>
<p>Para redefinir uma propriedade de uma pool ou dataset para o estado padrão, use <code>zfs inherit</code>:
</p>
<pre># zfs inherit -rS atime &lt;pool&gt;
# zfs inherit -rS atime &lt;pool&gt;/&lt;dataset&gt;
</pre>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Atenção:</strong> Usar a opção <code>-r</code> redefinirá recursivamente todos os datasets na zpool.</div>
<h3><span class="mw-headline" id="Esfregar">Esfregar</span></h3>
<p>Quando dado é lido e o ZFS encontra erro, ele é silenciosamente reparado quando possível, reescrito de volta no disco e gera-se um log para que você possa obter uma visão geral de erros em suas pools. Não existe fsck ou ferramenta equivalenete para o ZFS. Ao invés disto, o ZFS suporta a opção de "esfregar". Isto percorre todos os dados na pool e verifica se todos os blocos podem ser lidos.
</p>
<p>Para esfregar uma pool:
</p>
<pre># zpool scrub &lt;pool&gt;
</pre>
<p>Para cancelar um esfregamento em execução:
</p>
<pre># zpool scrub -s &lt;pool&gt;
</pre>
<h4>
<span id="Com_que_frequ.C3.AAncia_devo_fazer_isto.3F"></span><span class="mw-headline" id="Com_que_frequência_devo_fazer_isto?">Com que frequência devo fazer isto?</span>
</h4>
<p>Da postagem no blog da Oracle <a rel="nofollow" class="external text" href="https://blogs.oracle.com/wonders-of-zfs-storage/disk-scrub-why-and-when-v2">Disk Scrub - Why and When?</a>:
</p>
<dl><dd>Esta pergunta é desafiadora até para o Supporte responder, porque como sempre a resposta correta é "Depende". Então antes que eu ofereça orientações gerais, aqui estão algumas dicas para lhe auxiliar a criar uma resposta mais apropriada para o seu padrão de uso.</dd></dl>
<dl><dd><ul>
<li>Qual é a expiração do seu backup mais antigo? Você provavalmente deve esfregar seus dados pelo menos com a mesma frequência que as suas fitas mais antigas expiram para que você tenha um ponto de restauração que você saiba que é bom.</li>
<li>Com que frequência você experiencia falhas de disco? Embora o recrutamento de um disco hot-spare invoque um "resilver" -- um esfregamento direcionado apenas do VDEV que perdeu um disco -- você deve provavelmente esfregar pelo menos com a mesma frequência que você experiencia, em média, falhas de discos no seu ambiente.</li>
<li>Com que frequência o pedaço de dado mais antigo em seu disco é lido? Você deve esfregar ocasionalmente para que dados muito antigos e muito velhos não experienciem apodrecimento de bit "bit-rot" e morram sem que você perceba.</li>
</ul></dd></dl>
<dl><dd>Se para qualquer uma das perguntas acima sua resposta seja "Não sei", a orientação geral é: você provavelmente deve esfregar sua zpool pelo menos uma vez por mês. É um agendamento que funciona bem para a maioria dos casos de uso, provê tempo suficiente para esfregamentos terminarem antes que outros sejam iniciados inclusive nos sistemas com maior carga, até mesmo deve concluir em zpools bem grandes (192 discos ou mais) antes que discos falhem.</dd></dl>
<p>No <a rel="nofollow" class="external text" href="https://pthree.org/2012/12/11/zfs-administration-part-vi-scrub-and-resilver/">ZFS Administration Guide</a>, de Aaron Toponce, ele aconselha esfregar discos de consumidores pelo menos uma vez por semana.
</p>
<h4>
<span id="Iniciar_com_servi.C3.A7o_ou_timer"></span><span class="mw-headline" id="Iniciar_com_serviço_ou_timer">Iniciar com serviço ou timer</span>
</h4>
<p>Usar um temporizador/serviço do <a href="../pt/Systemd.html" title="Systemd (Português)">systemd</a> é possível para automaticamente esfregar pools.
</p>
<p>Para realizar o esfregamento mensalmente de uma pool específica:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/zfs-scrub@.timer</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Esfregar mensalmente a zpool em %i

[Timer]
OnCalendar=monthly
AccuracySec=1h
Persistent=true

[Install]
WantedBy=multi-user.target</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/zfs-scrub@.service</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Esfregar zpool em %i

[Service]
Nice=19
IOSchedulingClass=idle
KillSignal=SIGINT
ExecStart=/usr/bin/zpool scrub %i

[Install]
WantedBy=multi-user.target</pre>
<p><a href="../pt/Systemd.html#Usando_units" title="Systemd (Português)">Habilite e inicie</a> a unidade <code>zfs-scrub@<i>pool-pra-esfregar</i>.timer</code> para esfregar mensalmente a pool especificada.
</p>
<h3><span class="mw-headline" id="Cache_em_SSD">Cache em SSD</span></h3>
<p>Você pode adicionar dispositivos SSD com a inteção de gravar logs (ZIL ou SLOG externo) e também como um cache de substituição adaptável da camada 2 (L2ARC). O processo para adicioná-los é muito semelhante à adição de um novo VDEV.
</p>
<p>Todas as referências abaixo à identificação do dispositivo são os IDs em  <code>/dev/disk/by-id/*</code>.
</p>
<h4><span class="mw-headline" id="SLOG">SLOG</span></h4>
<p>Para adicionar um SLOG espelhado:
</p>
<pre> # zpool add &lt;pool&gt; log mirror &lt;identificação-do-dispositivo-1&gt; &lt;identificação-do-dispositivo-2&gt;
</pre>
<p>Ou para acrescentar um único dispositivo SLOG (inseguro):
</p>
<pre> # zpool add &lt;pool&gt; log &lt;identificação-do-dispositivo&gt;
</pre>
<p>Como o dispositivo SLOG armazena dado que não foi escrito na pool, é importante usar dispositivos que podem finalizar escritas quando a energia é perdida. Também é importante utilizar redundância, já que a falha em um único dispositivo pode causar perda de dados. Além do mais, o SLOG é apenas utilizado para sincronizar escritas, então pode não auxiliar com melhorias de desempenho.
</p>
<h4><span class="mw-headline" id="L2ARC">L2ARC</span></h4>
<p>Para acrescentar L2ARC:
</p>
<pre> # zpool add &lt;pool&gt; cache &lt;identificação-do-dispositivo&gt;
</pre>
<p>Como cada bloco armazenado no L2ARC utiliza uma pequena quantidade de memória, geralmente só é útil em cargas onde o dado quente é *maior* que a quantidade total de memória que pode caber no computador, mas pequena suficiente para caber no L2ARC. O L2ARC também é limpo durante a reinicialização e é somente um cache de leitura, então a redundância é desnecessária. Não intuitivamente, L2ARC pode impactar no desempenho pois utiliza parte da memória que seria utilizada pelo ARC.
</p>
<h3><span class="mw-headline" id="ZVOLs">ZVOLs</span></h3>
<p>Volumes de ZFS (ZVOLs) podem sofrer dos mesmos problemas relacionados à tamanho de blocos que SGBDRs, mas vale notar que o tamanho de registro padrão de ZVOLs já é 8KiB. Se possível, é melhor alinhar partições contidas em um ZVOL para o tamanho do seu recordsize (versões atuais de fdisk e gdisk por padrão automaticamente alinham segmentos de 1MiB, o que resolve), e tamanhos de blocos de sistema de arquivos para o mesmo tamanho. Mais do que isso, você pode ajustar o <b>recordsize</b> para acomodar os dados dentro do ZVOL conforme necessário (apesar que 8 KiB tende a ser um bom valor para a maioria dos sistemas de arquivos, mesmo ao utilizar blocos de 4 KiB naquele nível).
</p>
<h4>
<span id="RAIDZ_e_discos_f.C3.ADsicos_com_Formata.C3.A7.C3.A3o_Avan.C3.A7ada"></span><span class="mw-headline" id="RAIDZ_e_discos_físicos_com_Formatação_Avançada">RAIDZ e discos físicos com Formatação Avançada</span>
</h4>
<p>Cada bloco em um ZVOL possui seu próprio disco de paridade, e se você tiver mídias físicas com tamanhos de blocos de 4096B, 8192B ou assim por diante, a paridade precisa ser armazenada em blocos físicos inteiros, e isto pode drasticamente aumentar os requerimentos de espaço de um ZVOL, necessitando 2× ou mais capacidade de armazenamento do que a capacidade lógica do ZVOL. Definindo o <b>recordsize</b> como 16k ou 32k pode ajudar a reduzir drasticamente este efeito.
</p>
<p>Veja <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/issues/1807">ZFS on Linux issue #1807 para detalhes</a>
</p>
<h3>
<span id="Escalonador_de_E.2FS"></span><span class="mw-headline" id="Escalonador_de_E/S">Escalonador de E/S</span>
</h3>
<p>Quando a pool é importada, para vdevs que ocupam to o disco, o escalonador de E/S de dispositivos de bloco é definido através do <code>zfs_vdev_scheduler</code> <a rel="nofollow" class="external autonumber" href="https://github.com/zfsonlinux/zfs/wiki/ZFS-on-Linux-Module-Parameters#zfs_vdev_scheduler">[5]</a> (conteúdo em inglês). Os escalonadores mais comuns são <i>noop</i>, <i>cfq</i>, <i>bfq</i>, e <i>deadline</i>.
</p>
<p>Em alguns casos, o escalonador não é mutável ao usar este método. Escalonadores que não podem ser mudados são: <i>scsi_mq</i> and <i>none</i>. Nestes casos, o escalonador permanece inalterado e uma mensagem de erro pode ser relatada nos logs. <a href="../pt/Improving_performance.html#Mudando_o_escalonador_de_E/S" class="mw-redirect" title="Melhorando o desempenho">Definindo manualmente</a> um dos escalonadores comuns através do <code>zfs_vdev_scheduler</code> pode resultar em desempenho mais consistente.
</p>
<h2>
<span id="Solu.C3.A7.C3.A3o_de_Problemas"></span><span class="mw-headline" id="Solução_de_Problemas">Solução de Problemas</span>
</h2>
<h3>
<span id="Cria.C3.A7.C3.A3o_de_uma_zpool_falha"></span><span class="mw-headline" id="Criação_de_uma_zpool_falha">Criação de uma zpool falha</span>
</h3>
<p>Se o seguinte erro ocorrer, então é possível consertar.
</p>
<pre># the Kernel failed to rescan the partition table: 16
# cannot label 'sdc': try using parted(8) and then provide a specific slice: -1
</pre>
<p>Uma razão para isto occorer é porque o <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/issues/2582">ZFS expera que a criação de uma pool leve menos que 1 segundo</a> (conteúdo em inglês). Esta é uma suposição razoável em condições normais, mas em muitas situações, pode levar mais tempo. Cada dispositivo precisará ser limpo novamente antes que alguma tentativa possa ser feita.
</p>
<pre># parted /dev/sda rm 1
# parted /dev/sda rm 1
# dd if=/dev/zero of=/dev/sdb bs=512 count=1
# zpool labelclear /dev/sda
</pre>
<p>Uma criação com força bruta pode ser tentada repetidamente, e, com alguma sorte, a criação da ZPool levará menos que 1 segundo.
Uma causa para lentidão na criação pode ser picos de leitura e gravações lentos no dispositivo. Causando leitura no disco em paralelo à criação da ZPool, é possível acelerar a velocidade do pico.
</p>
<pre># dd if=/dev/sda of=/dev/null
</pre>
<p>Isto pode ser feito com múltiplos dispositivos salvando o comando acima para cada dispositivo de armazenamento em uma linha diferente e executando
</p>
<pre># cat $ARQUIVO | parallel
</pre>
<p>Então, rode a criação da ZPool ao mesmo tempo.
</p>
<h3>
<span id="ZFS_est.C3.A1_utilizando_muita_RAM"></span><span class="mw-headline" id="ZFS_está_utilizando_muita_RAM">ZFS está utilizando muita RAM</span>
</h3>
<p>Por padrão, o ZFS realiza o cache de operações nos arquivos (<a href="https://en.wikipedia.org/wiki/Adaptive_replacement_cache" class="extiw" title="wikipedia:Adaptive replacement cache">ARC</a> - conteúdo em inglês), chegando a utilizar até ⅔ da memória disponível na máquina. Para ajustar o tamanho do ARC, acrescente o seguinte conteúdo à lista de <a href="../pt/Kernel_parameters.html" class="mw-redirect" title="Parâmetros do kernel">Parâmetros do kernel</a>:
</p>
<pre>zfs.zfs_arc_max=536870912 # (para 512MiB)
</pre>
<p>No caso em que o valor padrão de <code>zfs_arc_min</code> (1/32 da memória do sistema) seja maior do que o especificado <code>zfs_arc_max</code>, também é necessário acrescentar o seguinte na lista de <a href="../pt/Kernel_parameters.html" class="mw-redirect" title="Parâmetros do kernel">Parâmetros do kernel</a>:
</p>
<pre>zfs.zfs_arc_min=268435456 # (para 256MiB, precisa ser inferior ao do zfs.zfs_arc_max)
</pre>
<p>Para uma descrição mais detalhada, assim como outras opções de configuração, veja <a rel="nofollow" class="external text" href="https://wiki.gentoo.org/wiki/ZFS#ARC">gentoo-wiki:zfs#arc (Conteúdo em inglês)</a>.
</p>
<h3>
<span id="N.C3.A3o_cont.C3.A9m_um_r.C3.B3tulo_EFI"></span><span class="mw-headline" id="Não_contém_um_rótulo_EFI">Não contém um rótulo EFI</span>
</h3>
<p>O seguinte erro irá ocorrer ao tentar criar o sistema de arquivos ZFS,
</p>
<pre>/dev/disk/by-id/&lt;id&gt; does not contain an EFI label but it may contain partition
</pre>
<p>Para supererar este erro, use <code>-f</code> junto ao comando zfs create.
</p>
<h3>
<span id="N.C3.A3o_encontrou_hostid"></span><span class="mw-headline" id="Não_encontrou_hostid">Não encontrou hostid</span>
</h3>
<p>Um erro que ocorre durante a inicialização com as seguintes linhas aparece antes da saída do scipt de inicialização:
</p>
<pre>ZFS: No hostid found on Kernel command line or /etc/hostid.
</pre>
<p>Este aviso ocorre pois o módulo do ZFS não tem acesso ao SPL hospedado. Existem duas soluções para isso. Ou insira a identificação do anfitrião (hostid) nos <a href="../pt/Kernel_parameters.html" class="mw-redirect" title="Parâmetros do kernel">Parâmetros do kernel</a> no gerenciador de inicialização, colocando <code>spl.spl_hostid=0x00bab10c</code>.
Ou garanta que existe um hostid em <code>/etc/hostid</code>, então <a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">Gere novamente o initramfs</a>. Que irá copiar o hostid para a imagem do initramfs.
</p>
<h3>
<span id="Pool_n.C3.A3o_encontrada_ao_iniciar_de_dispositivos_SAS.2FSCSI"></span><span class="mw-headline" id="Pool_não_encontrada_ao_iniciar_de_dispositivos_SAS/SCSI">Pool não encontrada ao iniciar de dispositivos SAS/SCSI</span>
</h3>
<p>Caso você esteja iniciando à partir de um SAS/SCSI, você pode ocasionalmente ter problemas de inicialização nos quais a pool que seu sistema está tentando utilizar para inicialização não pode ser encontrada. Uma possível razão para isto é que seus dispositivos foram inicializados tarde demais durante o processo. Isso significa que o ZFS não pode encontrar nenhum dispositivo no instante que tentou montar a pool.
</p>
<p>Neste caso, você deve forçar o driver SCSI a aguardar para que os dispositivos estejam disponíveis antes de continuar. Você pode fazer isto inserindo o seguinte em <code>/etc/modprobe.d/zfs.conf</code>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/modprobe.d/zfs.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">options scsi_mod scan=sync</pre>
<p>Depois, <a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">gere novamente o initramfs</a>.
</p>
<p>Isto funciona pois o gancho do ZFS irá copiar o arquivo em <code>/etc/modprobe.d/zfs.conf</code> para o initcpio, que será então utilizado ao ser construído.
</p>
<h3>
<span id="Durante_a_inicializa.C3.A7.C3.A3o.2C_a_pool_do_ZFS_n.C3.A3o_monta_afirmando:_.22pool_may_be_in_use_from_other_system.22"></span><span class="mw-headline" id='Durante_a_inicialização,_a_pool_do_ZFS_não_monta_afirmando:_"pool_may_be_in_use_from_other_system"'>Durante a inicialização, a pool do ZFS não monta afirmando: "pool may be in use from other system"</span>
</h3>
<h4>
<span id="Pool_n.C3.A3o_exportada"></span><span class="mw-headline" id="Pool_não_exportada">Pool não exportada</span>
</h4>
<p>Se a nova instalação não inicializa pois a zpool não pôde ser importada. Faça chroot para a instalação e exporte apropriadamente a zpool. Veja <a href="#Conserto_de_emerg%C3%AAncia_em_chroot_com_archzfs">#Conserto de emergência em chroot com archzfs</a>.
</p>
<p>Uma vez dentro do ambiente chroot, carrege o módulo ZFS e force a importação da zpool:
</p>
<pre># zpool import -a -f
</pre>
<p>Agora exporte a pool
</p>
<pre># zpool export &lt;pool&gt;
</pre>
<p>Para ver as pools disponíveis:
</p>
<pre># zpool status
</pre>
<p>É necessário exportar a pool devido à forma que o ZFS utiliza o hostid para descobrir o sistema no qual a zpool foi criada. O hostid é gerado parcialmente baseado na configuração da rede. Durante a instalação na archiso, a configuração de rede pode estar diferente, gerando um hostid diferente daquele contido na nova instalação. Uma vez que o sistema de arquivos ZFS é exportado e então reimportado na nova instalação, a hostid é redefinida. Veja o conteúdo em inglês <a rel="nofollow" class="external text" href="https://web.archive.org/web/20151101094022/http://osdir.com/ml/zfs-discuss/2011-06/msg00227.html">Re: Howto zpool import/export automatically? - msg#00227</a>.
</p>
<p>Se o ZFS reclamar "a pool pode já estar em uso por outro sistema" mesmo após reinicializar, faça a exportação apropriadamente como descrito acima, então <a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">gere novamente o initramfs</a> no sistema normalmente inicializado.
</p>
<h4><span class="mw-headline" id="hostid_incorreta">hostid incorreta</span></h4>
<p>Verifique duas vezes se a pool foi exportada corretamente. Exportar a zpool limpa a hostid que marca a posse. Então durante a primeira inicialização, a zpool deve montar corretamente, caso não, exite outro problema.
</p>
<p>Reinicie novamente, se a pool do zfs não for montada, significa que a hostid ainda não está propriamente definida durante o início da etapa de inicialização e isto confunde o ZFS. Manualmente informe ao zfs o número correto, uma vez que a hostid esteja coerente entre as reinicializações, a zpool montará corretamente.
</p>
<p>Inicie utilizando zfs_force e escreva a hostid.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ hostid</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">0a0af0f8
</pre>
<p>Este número deve ser acrescentado aos <a href="../pt/Kernel_parameters.html" class="mw-redirect" title="Parâmetros do kernel">Parâmetros do kernel</a> como <code>spl.spl_hostid=0x0a0af0f8</code>. Outra solução é escrever a hostid dentro da imagem de initramfs, veja a explicação no <a href="../en/Install_Arch_Linux_on_ZFS.html#Configure_systemd_ZFS_mounts" class="mw-redirect" title="Installing Arch Linux on ZFS">guia de instalação</a>.
</p>
<p>Usuários podem sempre ignorar a verificação e acrescentar <code>zfs_force=1</code> nos <a href="../pt/Kernel_parameters.html" class="mw-redirect" title="Parâmetros do kernel">Parâmetros do kernel</a>, mas não é aconselhável tornar esta a solução permanente.
</p>
<h3><span class="mw-headline" id="Dispositivos_possuem_diferentes_alinhamentos_de_setor">Dispositivos possuem diferentes alinhamentos de setor</span></h3>
<p>Uma vez que um dispositivo estiver com defeito, ele deve ser substituído o mais rapidamente possível, por um aparelho idêntico.
</p>
<pre># zpool replace bigdata ata-ST3000DM001-9YN166_S1F0KDGY ata-ST3000DM001-1CH166_W1F478BD -f
</pre>
<p>Mas, neste exemplo, o seguinte erro ocorre:
</p>
<pre>cannot replace ata-ST3000DM001-9YN166_S1F0KDGY with ata-ST3000DM001-1CH166_W1F478BD: devices have different sector alignment
</pre>
<p>ZFS utiliza a opção ashift para se ajustar aos tamanhos de blocos físicos. Ao substituir o disco com defeito, ZFS tenta utilizar <code>ashift=12</code>, mas o discodefeituoso possivelmente utiliza outro valor de ashift (possivelmente <code>ashift=9</code>), e isto causa o erro acima.
</p>
<p>Para Discos com Formatação Avançada com tamanho de bloco de 4KiB, um valor de ashift de 12 é recomendado para melhor desempenho. Veja os conteúdos em inglês <a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/wiki/faq#performance-considerations">1.10 What’s going on with performance?</a> e <a rel="nofollow" class="external text" href="http://wiki.illumos.org/display/illumos/ZFS+and+Advanced+Format+disks">ZFS and Advanced Format disks</a>.
</p>
<p>Use zdb para descobrir o valor de ashift para a ZPool - <code>zdb </code> - então use o argumento <code>-o</code> para definir o ashift no dispositivo que substituirá:
</p>
<pre># zpool replace bigdata ata-ST3000DM001-9YN166_S1F0KDGY ata-ST3000DM001-1CH166_W1F478BD -o ashift=9 -f
</pre>
<p>Verifique o status da zpool para confirmar:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># zpool status -v</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">pool: bigdata
state: DEGRADED
status: One or more devices is currently being resilvered.  The pool will
        continue to function, possibly in a degraded state.
action: Wait for the resilver to complete.
scan: resilver in progress since Mon Jun 16 11:16:28 2014
    10.3G scanned out of 5.90T at 81.7M/s, 20h59m to go
    2.57G resilvered, 0.17% done
config:

        NAME                                   STATE     READ WRITE CKSUM
        bigdata                                DEGRADED     0     0     0
        raidz1-0                               DEGRADED     0     0     0
            replacing-0                        OFFLINE      0     0     0
            ata-ST3000DM001-9YN166_S1F0KDGY    OFFLINE      0     0     0
            ata-ST3000DM001-1CH166_W1F478BD    ONLINE       0     0     0  (resilvering)
            ata-ST3000DM001-9YN166_S1F0JKRR    ONLINE       0     0     0
            ata-ST3000DM001-9YN166_S1F0KBP8    ONLINE       0     0     0
            ata-ST3000DM001-9YN166_S1F0JTM1    ONLINE       0     0     0

errors: No known data errors
</pre>
<h3>
<span id="Resilver_de_pool_parado.2Fpreso.2Freiniciando.2Flento.3F"></span><span class="mw-headline" id="Resilver_de_pool_parado/preso/reiniciando/lento?">Resilver de pool parado/preso/reiniciando/lento?</span>
</h3>
<p>De acordo com o github do ZnL, este é um problema conhecido desde 2012 com ZFS-ZED, que faz com que o processo de resilver constantemente reinicie, as vezes fique parado/preso e geralmente lento em alguns hardwares. A mitigação mais simples é parar o zfs-zed.service até que o resilver complete.
</p>
<h3>
<span id="Consertar_inicializa.C3.A7.C3.A3o_lenta_causada_por_falha_na_importa.C3.A7.C3.A3o_de_pools_indispon.C3.ADveis_no_zpool.cache_do_initramfs"></span><span class="mw-headline" id="Consertar_inicialização_lenta_causada_por_falha_na_importação_de_pools_indisponíveis_no_zpool.cache_do_initramfs">Consertar inicialização lenta causada por falha na importação de pools indisponíveis no zpool.cache do initramfs</span>
</h3>
<p>Seu tempo até inicializar pode ser significativamente impactado se a sua atualização do initramfs (ex: ao fazer a atualização do Kernel) quando você possui adicionais pools mas que não são permanentemente conectadas importadas porque estas pools serão acrescentadas ao zpool.cache e o ZFS tentará importar estas pools adicionais a cada inicialização, independentemente se você exportou e removeu do seu zpool.cache normal.
</p>
<p>Se você perceber que o ZFS está tentando importar pools indisponíveis durante a inicialização, primeiro rode:
</p>
<pre>$ zdb -C
</pre>
<p>Para ver em seu zpool.cache pools que você não quer importadas durante a inicialização. Se este comando estiver mostrando pools adicionais, e não atualmente disponíveis, rode:
</p>
<pre># zpool set cachefile=/etc/zfs/zpool.cache zroot
</pre>
<p>Para limpar o zpool.cache de quaisquer outras pools que não possuírem o nome zrool. Às vezes não é necessário redefinir o zpool.cache, mas simplesmente <a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">gerar o initramfs novamente</a>
</p>
<h2><span class="mw-headline" id="Dicas_e_truques">Dicas e truques</span></h2>
<h3><span class="mw-headline" id="Embutir_os_pacotes_do_archzfs_na_archiso">Embutir os pacotes do archzfs na archiso</span></h3>
<p>Siga os passos da <a href="../pt/Archiso.html" title="Archiso (Português)">Archiso</a> para criar uma imagem live completamente funcional de CD/DVD/USB do Arch Linux.
</p>
<p>Habilite o repositório do <a href="../en/Unofficial_user_repositories.html#archzfs" title="Unofficial user repositories">archzfs</a>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">~/archlive/pacman.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
[archzfs]
Server = http://archzfs.com/$repo/x86_64
SigLevel = Optional TrustAll
</pre>
<p>Acrescente o grupo <code>archzfs-linux</code> à lista de pacotes a serem instalados (o repositório do <code>archzfs</code> fornece os pacotes apenas para a arquitetura x86_64).
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">~/archlive/packages.x86_64</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
archzfs-linux
</pre>
<p>Complete a <a href="../pt/Archiso.html#Construir_a_ISO" title="Archiso (Português)">compilação da ISO</a> para finalmente criar a ISO.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> Se você posteriormente tiver problemas ao rodar modprobe zfs, você deve incluir linux-headers no packages.x86_64.</div>
<h3>
<span id="Snapshots_autom.C3.A1ticos"></span><span class="mw-headline" id="Snapshots_automáticos">Snapshots automáticos</span>
</h3>
<h4>
<span id="Servi.C3.A7o_de_snapshots_autom.C3.A1ticos_do_ZFS_para_o_Linux"></span><span class="mw-headline" id="Serviço_de_snapshots_automáticos_do_ZFS_para_o_Linux">Serviço de snapshots automáticos do ZFS para o Linux</span>
</h4>
<p>O pacote <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zfs-auto-snapshot-git/">zfs-auto-snapshot-git</a></span><sup><small>AUR</small></sup> <a href="../pt/Arch_User_Repository.html" class="mw-redirect" title="AUR (Português)">AUR</a> fornece um script em shell para automatizar o gerenciamento de snapshots, com cada um recebendo o nome da data e rótulo (por hora, por dia, etc), fornecendo a obtenção rápida e conveniente de snapshots de todos os datasets do ZFS. O pacote também instala tarefas do cron para gerar snapshots a cada 15 minutos, hora, dia, semana e mês. Opcionalmente, ajuste o parâmetro <code>--keep</code> dos padrões dependendo da quantidade de tempo que você deseja que os snapshots existam (para o script mensal, a retenção é de até 1 ano).
</p>
<p>Para impedir que um snapshots seja criado para um dataset específico, defina <code>com.sun:auto-snapshot=false</code> nele. Similarmente, tenha um controle mais refinado também definindo por rótulo, se, por exemplo, nenhum snapshot deva ser mantido para o período mensal definindo <code>com.sun:auto-snapshot:monthly=false</code>.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Nota:</strong> zfs-auto-snapshot-git não criará snapshots durante o <a href="#Esfregar">esfregamento</a>. É possível sobrescrever isto (<a href="../pt/Systemd.html#Editando_units_fornecidas" title="Systemd (Português)">editando a unidade do systemd fornecida</a>) e removendo <code>--skip-scrub</code> na linha <code>ExecStart</code>.</div>
<p>Com o pacote já instalado, <a href="../pt/Systemd/Timers.html" title="Systemd (Português)/Timers (Português)">habilite e inicie os temporizadores selecionados</a> (<code>zfs-auto-snapshot-{frequent,daily,weekly,monthly}.timer</code>).
</p>
<h4><span class="mw-headline" id="zrepl">zrepl</span></h4>
<p>O pacote zrepl <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/zrepl/">zrepl</a></span><sup><small>AUR</small></sup> do <a href="../en/Arch_User_Repository.html" class="mw-redirect" title="AUR">AUR</a> fornece um serviço de replicação automático, que pode ser também utilizado como um serviço para tirar snapshots, como o <a href="../pt/Snapper.html" title="Snapper (Português)">snapper</a>.
</p>
<p>Para detalhes em como configurar o daemon do zrepl, veja a <a rel="nofollow" class="external text" href="https://zrepl.github.io/">documentação</a> do zrepl. O arquivo de configuração deve estar em <code>/etc/zrepl/zrepl.yml</code>. Então, execute <code>zrepl configcheck</code> para ter certeza que a sintaxe do arquivo de configuração está correta. Finalmente, habilite <code>zrepl.service</code>.
</p>
<h3><span class="mw-headline" id="Criando_um_compartilhamento">Criando um compartilhamento</span></h3>
<p>ZFS possui suporte para criares compartilhamentos (shares) por <a href="../en/NFS.html" title="NFS">NFS</a> ou <a href="../en/Samba.html" class="mw-redirect" title="SMB">SMB</a>.
</p>
<h4><span class="mw-headline" id="NFS">NFS</span></h4>
<p>Assegure-se que <a href="../en/NFS.html" title="NFS">NFS</a> foi instalado/configurado, note que não há necessidade de editar o arquivo <code>/etc/exports</code>. Para compartilhar em cima de NFS, os serviços <code>nfs-server.service</code> e <code>zfs-share.service</code> deve ser <a href="../pt/Systemd.html#Usando_units" class="mw-redirect" title="Iniciado">iniciado</a>.
</p>
<p>Para tornar uma pool disponível na rede:
</p>
<pre># zfs set sharenfs=on &lt;nome-da-pool&gt;
</pre>
<p>Para tornar um dataset disponível na rede:
</p>
<pre># zfs set sharenfs=on &lt;nome-da-pool&gt;/&lt;nome-do-dataset&gt;
</pre>
<p>Para permitir acesso de leitura/escrita em um intervalo específico de IPs:
</p>
<pre># zfs set sharenfs="rw=@192.168.1.100/24,rw=@10.0.0.0/24" &lt;nome-da-pool&gt;/&lt;nome-do-dataset&gt;
</pre>
<p>Para verificar se o dataset foi exportado com sucesso:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># showmount -e <i>hostname</i></pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">Export list for hostname:
/path/of/dataset 192.168.1.100/24
</pre>
<p>Para ver as exportações atualmente carregadas com mais detalhes, use:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># exportfs -v</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">/path/of/dataset
    192.168.1.100/24(sync,wdelay,hide,no_subtree_check,mountpoint,sec=sys,rw,secure,no_root_squash,no_all_squash)</pre>
<p>Para ver a lista atual de compartilhamentos em NFS do ZFS:
</p>
<pre># zfs get sharenfs
</pre>
<h4><span class="mw-headline" id="SMB">SMB</span></h4>
<p>Ao compartilhar através de SMB, usar <code>usershares</code> em <code>/etc/samba/smb.conf</code> permitirá ao ZFS configurar e criar os compartilhamentos. 
</p>
<pre># [global]
#    usershare path = /var/lib/samba/usershares
#    usershare max shares = 100
#    usershare allow guests = yes
#    usershare owner only = no</pre>
<p>Crie e defina permissões no diretório do usuário como root.
</p>
<pre># mkdir /var/lib/samba/usershares
# chmod +t /var/lib/samba/usershares
</pre>
<p>Para tornar disponível uma pool na rede:
</p>
<pre># zfs set sharesmb=on &lt;nome-da-zpool&gt;
</pre>
<p>Para tornar disponível um dataset na rede:
</p>
<pre># zfs set sharesmb=on &lt;nome-da-zpool&gt;/&lt;nome-do-dataset&gt;
</pre>
<p>Para verificar se o dataset foi exportado com sucesso:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># smbclient -L localhost -U%</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">        Sharename       Type      Comment
        ---------       ----      -------
        IPC$            IPC       IPC Service (SMB Server Name)
        &lt;nome-da-zpool&gt;_&lt;nome-do-dataset&gt;        Disk      Comment: caminho/do/dataset
SMB1 disabled -- no workgroup available
</pre>
<p>Para ver a lista atual de compartilhamentos em SMB do ZFS:
</p>
<pre># zfs get sharesmb
</pre>
<h3><span class="mw-headline" id="Criptografia_no_ZFS_utilizando_dm-crypt">Criptografia no ZFS utilizando dm-crypt</span></h3>
<p>A versão estável do ZFS no Linux não possuía suporte à criptografia (agora está disponível, veja <a href="#Criptografia_nativa">#Criptografia nativa</a>), mas zpools podem ser criados em dispositivos de bloco do dm-crypt. Já que a zpool é criada com a abstração plain-text (em texto simples, ou seja, não criptografado), é possível ter os dados criptografados e ainda aproveitar todas as vantagens do ZFS como deduplicação, compressão e robustez de dados.
</p>
<p>dm-crypt, possivelmente através de LUKS, cria dispositivos em <code>/dev/mapper</code> e o nome é fixo. Então somente é necessário mudar o comando <code>zpool create</code> para apontar para aqueles nomes. A ideia é configurar o sistema para criar os dispositivos de bloco em <code>/dev/mapper</code> e importar as ZPools de lá. Como as ZPools podem ser criadas em múltiplos dispositivos (em RAID, espelhados, em faixas/striping, ...), é importante que todos os dispositivos estejam criptografados, caso não, a proteção poderá estar parcialmente perdida.
</p>
<p>Por exemplo, uma ZPool criptografada pode ser criada usando somente dm-crypt (sem LUKS) com:
</p>
<pre># cryptsetup --hash=sha512 --cipher=twofish-xts-plain64 --offset=0 \
             --key-file=/dev/sdZ --key-size=512 open --type=plain /dev/sdX enc
# zpool create zroot /dev/mapper/enc
</pre>
<p>No caso de uma pool para o sistema de arquivos do root, a linha dos HOOKS do <code>/etc/mkinitcpio.conf</code> precisa permitir o teclado para a senha, criar os dispositivos e carregar as pools, portanto, ficará similar ao seguinte:
</p>
<pre>HOOKS="... keyboard encrypt zfs ..."
</pre>
<p>Já que o nome <code>/dev/mapper/enc</code> é fixo, nenhum erro de importação ocorrerá.
</p>
<p>Criar pools criptografadas funciona bem, no entanto, caso precise criptografar diretórios, por exemplo para proteger os diretórios pessoas dos usuários, o ZFS perde parte da funcionalidade.
</p>
<p>ZFS enxergará o dado criptografado, não a abstração em texto simples, então a compressão e a deduplicação não funcionará. A razão é que o dado criptografado tem sempre alta entropia, fazendo com que a compressão seja ineficiente e até mesmo da mesma entrada, ocorrem saídas diferentes (graças ao <i>salt</i>), tornando a deduplicação impossível. Para reduzir sobrecarga desnecessária, é possível criar um subsistema de arquivos para cada diretório criptografado e usar <a href="../en/ECryptfs.html" title="ECryptfs">eCryptfs</a> nele.
</p>
<p>Por exemplo, para ter o /home criptografado: (as duas senhas, de criptografia e login, devem ser a mesma).
</p>
<pre># zfs create -o compression=off -o dedup=off -o mountpoint=/home/&lt;nome-do-usuário&gt; &lt;zpool&gt;/&lt;nome-do-usuário&gt;
# useradd -m &lt;nome-do-usuário&gt;
# passwd &lt;nome-do-usuário&gt;
# ecryptfs-migrate-home -u &lt;nome-do-usuário&gt;
&lt;Faça o login e complete o procedimento com o ecryptfs-unwrap-passphrase&gt;
</pre>
<h3>
<span id="Conserto_de_emerg.C3.AAncia_em_chroot_com_archzfs"></span><span class="mw-headline" id="Conserto_de_emergência_em_chroot_com_archzfs">Conserto de emergência em chroot com archzfs</span>
</h3>
<p>Para entrar no sistema de arquivos ZFS à partir do sistema live para manutenção, existem duas opções:
</p>
<ol>
<li>Construa uma archiso personalizada com ZFS como descrito em <a href="#Embutir_os_pacotes_do_archzfs_na_archiso">#Embutir os pacotes do archzfs na archiso</a>.</li>
<li>Inicialize na archiso oficial mais recente disponível, garanta acesso à rede, então habilite o repositório <a href="../en/Unofficial_user_repositories.html#archzfs" title="Unofficial user repositories">archzfs</a> dentro do sistema live como de costume, sincronize o banco de dados de pacotes do pacman e instale o pacote <i>archzfs-archiso-linux</i>.</li>
</ol>
<p>Para iniciar a recuperação, carregue o módulo do ZFS:
</p>
<pre># modprobe zfs
</pre>
<p>Importe a pool:
</p>
<pre># zpool import -a -R /mnt
</pre>
<p>Monte as partições de inicialização (se existir alguma):
</p>
<pre># mount /dev/sda2 /mnt/boot
# mount /dev/sda1 /mnt/boot/efi
</pre>
<p>Faça o chroot para o sistema de arquivos ZFS:
</p>
<pre># arch-chroot /mnt /bin/bash
</pre>
<p>Verifique a versão do Kernel:
</p>
<pre># pacman -Qi linux
# uname -r
</pre>
<p>O comando uname mostrará a versão do Kernel na archiso. Se forem diferentes, execute depmod (no ambiente chroot) com a versão correta do Kernel da instalação do chroot:
</p>
<pre># depmod -a 3.6.9-1-ARCH (versão obtida com pacman -Qi linux mas usando os módulos respectivos do Kernel dentro do /lib/modules no chroot)
</pre>
<p>Isto carregará os módulos corretos do Kernel para a versão do Kernel instalada durante a instalação do chroot.
</p>
<p><a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">Gere novamente o initramfs</a>. Não deve haver erros.
</p>
<h3><span class="mw-headline" id="Montagem_com_bind">Montagem com bind</span></h3>
<p>Aqui, uma montagem com bind do /mnt/zfspool para /srv/nfs4/musica é criada. A configuração garante que a pool de ZFS esteja pronta antes que a montagem com bind seja criada.
</p>
<h4><span class="mw-headline" id="fstab">fstab</span></h4>
<p>Veja <span class="plainlinks archwiki-template-man" title="$ man 5 systemd.mount"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/systemd.mount.5">systemd.mount(5)</a></span> para mais informações em como o systemd converte fstab em unidades de montagem com o <span class="plainlinks archwiki-template-man" title="$ man 8 systemd-fstab-generator"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/systemd-fstab-generator.8">systemd-fstab-generator(8)</a></span>, ambos os conteúdos são em inglês.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/fstab</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">/mnt/zfspool		/srv/nfs4/musica		none	bind,defaults,nofail,x-systemd.requires=zfs-mount.service	0 0
</pre>
<h3>
<span id="Monitora.C3.A7.C3.A3o.2Fenvio_de_e-mails_em_eventos"></span><span class="mw-headline" id="Monitoração/envio_de_e-mails_em_eventos">Monitoração/envio de e-mails em eventos</span>
</h3>
<p>Veja <a rel="nofollow" class="external text" href="https://ramsdenj.com/2016/08/29/arch-linux-on-zfs-part-3-followup.html">ZED: The ZFS Event Daemon</a> para mais informações.
</p>
<p>Um encaminhador de e-mail, como <a href="../en/S-nail.html" title="S-nail">S-nail</a> é necessário para conseguir isto. Teste para assegurar que está funcionando corretamente.
</p>
<p>Descomente o seguinte no arquivo de configuração:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/zfs/zed.d/zed.rc</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;"> ZED_EMAIL_ADDR="root"
 ZED_EMAIL_PROG="mailx"
 ZED_NOTIFY_VERBOSE=0
 ZED_EMAIL_OPTS="-s '@SUBJECT@' @ADDRESS@"
</pre>
<p>Mude 'root' em <code>ZED_EMAIL_ADDR="root"</code> para o endereço de e-mail no qual deseja receber as notificações.
</p>
<p>Se você está mantendo o seu mailrc no seu diretório pessoal (home), você pode informar o mail para obter de lá configurando o <code>MAILRC</code>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/zfs/zed.d/zed.rc</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">export MAILRC=/home/&lt;usuário&gt;/.mailrc</pre>
<p>Isto funciona pois o ZED lê este arquivo, então o <code>mailx</code> enxergara esta variável de ambiente.
</p>
<p>Se você quer receber um e-mail, não importa o estado de sua pool, você deve definir <code>ZED_NOTIFY_VERBOSE=1</code>. Você precisa fazer isto temporariamente para testar.
</p>
<p><a href="../pt/Systemd.html#Usando_units" title="Systemd (Português)">Habilite e inicie</a> <code>zfs-zed.service</code>.
</p>
<p>Com <code>ZED_NOTIFY_VERBOSE=1</code>, você pode testar ao executar um esfregamento como root: <code>zpool scrub &lt;nome-da-pool&gt;</code>.
</p>
<h3><span class="mw-headline" id="Utilizar_comandos_de_shell_antes_e_depois_de_snapshots">Utilizar comandos de shell antes e depois de snapshots</span></h3>
<p>Já que é tão barato gerar um snapshot, podemos utilizar isto como medida de segurança para comandos sensíveis como atualização de pacotes e sistema. Se tirarmos um snapshot antes e um depois, é possível analisar as diferenças entre estes snapshots para descobrir o que foi modificado no sistema de arquivos depois que o comando foi executado. Além disso, podemos também voltar caso o resultado não tenha sido desejado.
</p>
<p>E.g.:
</p>
<pre># zfs snapshot -r zroot@pre
# pacman -Syu
# zfs snapshot -r zroot@post
# zfs diff zroot@pre zroot@post
# zfs rollback zroot@pre
</pre>
<p>Um utilitário que automatiza a criação anterior e posterior de snapshots envolvendo um comando do shell é <a rel="nofollow" class="external text" href="https://gist.github.com/erikw/eeec35be33e847c211acd886ffb145d5">znp</a>.
</p>
<p>E.g.:
</p>
<pre># znp pacman -Syu
# znp find / -name "algo*" -delete
</pre>
<p>E você conseguirá snapshots antes e depois do comando fornecido, e também a saída do comando é inserida em logs de arquivos para referência futura, para que saibamos qual comando criou o diff visto em um par de snapshots pré/pós.
</p>
<h3><span class="mw-headline" id="Desbloquear_remotamente_root_ZFS_criptografado">Desbloquear remotamente root ZFS criptografado</span></h3>
<p>A partir do <a rel="nofollow" class="external text" href="https://github.com/archzfs/archzfs/pull/261">PR #261</a>, <code>archzfs</code> suporta desbloqueio por SSH de datasets nativamente criptografados. Esta seção descreve como utilizar esta opção, e é amplamente baseada em <a href="../en/Dm-crypt/Specialties.html#Busybox_based_initramfs_(built_with_mkinitcpio)" title="Dm-crypt/Specialties">Dm-crypt/Specialties#Busybox based initramfs (built with mkinitcpio)</a>.
</p>
<ol>
<li>Instale <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=mkinitcpio-netconf">mkinitcpio-netconf</a></span> para fornecer os hooks (ganchos) para montar a rede inicial no espaço de usuário.</li>
<li>Escolha um servidor de SSH para usar no início do espaço do usuário. Opções mutualmente exclusivas são <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=mkinitcpio-tinyssh">mkinitcpio-tinyssh</a></span> ou <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=mkinitcpio-dropbear">mkinitcpio-dropbear</a></span>.
<ol><li>Se utilizar <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=mkinitcpio-tinyssh">mkinitcpio-tinyssh</a></span>, também é recomendado instalar <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=tinyssh">tinyssh</a></span> ou <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/tinyssh-convert-git/">tinyssh-convert-git</a></span><sup><small>AUR</small></sup>. Esta ferramenta converte uma hostkey do OpenSSH existente para o formato de chave do TinySSH, preservando a impressão digital da chave e evitando avisos de conexão. Os scripts de instalação do mkinitcpio do TinySSH e Dropbear automaticamente converterão hostkeys existentes ao gerar uma imagem nova de initpcio.</li></ol>
</li>
<li>Decida se irá utilizar uma chave de OpenSSH existente ou gerará uma nova (recomendado) para a máquina que se conectará e desbloqueará a máquina com ZFS criptografado. Copie a chave pública para <code>/etc/tinyssh/root_key</code> ou <code>/etc/dropbear/root_key</code>. Ao gerar a imagem de initcpio, este arquivo será adicionado às chaves autorizadas (<code>authorized_keys</code>) para o usuário root e somente é válida no ambiente initrd.</li>
</ol>
<p>Decide whether to use an existing OpenSSH key or generate a new one (recommended) for the host that will be connecting to and unlocking the encrypted ZFS machine. Copy the public key into <code>/etc/tinyssh/root_key</code> or <code>/etc/dropbear/root_key</code>. When generating the initcpio image, this file will be added to <code>authorized_keys</code> for the root user and is only valid in the initrd environment.
</p>
<ol>
<li>Acrescente o <a href="../pt/Kernel_parameters.html" class="mw-redirect" title="Parâmetros do kernel">parâmetro do Kernel</a> <code>ip=</code> à sua configuração do carregador de inicialização. A string <code>ip</code> é <a rel="nofollow" class="external text" href="https://docs.kernel.org/admin-guide/nfs/nfsroot.html">altamente configurável (conteúdo em inglês)</a>. Um exemplo simples com DHCP é mostrado abaixo.<pre>ip=:::::eth0:dhcp</pre>
</li>
<li>Edite <code>/etc/mkinitcpio.conf</code> para incluir os ganchos <code>netconf</code>, <code>dropbear</code> ou <code>tinyssh</code>, e <code>zfsencryptssh</code> antes do gancho <code>zfs</code>:<pre>HOOKS=(... netconf &lt;tinyssh&gt;|&lt;dropbear&gt; zfsencryptssh zfs ...)</pre>
</li>
<li>
<a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">Gere novamente o initramfs</a>.</li>
<li>Reinicie e teste!</li>
</ol>
<h4><span class="mw-headline" id="Mudando_a_porta_do_servidor_de_SSH">Mudando a porta do servidor de SSH</span></h4>
<p>Por padrão, ambos <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=mkinitcpio-tinyssh">mkinitcpio-tinyssh</a></span> e <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=mkinitcpio-dropbear">mkinitcpio-dropbear</a></span> escutam na porta <code>22</code>. Para mudar isto.
</p>
<p>Para <b>TinySSH</b>, copie <code>/usr/lib/initcpio/hooks/tinyssh</code> para <code>/etc/initcpio/hooks/tinyssh</code>, e encontre/modifique a seguinte linha na função <code>run_hook()</code>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/initcpio/hooks/tinyssh</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">/usr/bin/tcpserver -HRDl0 0.0.0.0 &lt;nova-porta&gt; /usr/sbin/tinysshd -v /etc/tinyssh/sshkeydir &amp;
</pre>
<p>Para <b>Dropbear</b>, copie <code>/usr/lib/initcpio/hooks/dropbear</code> para <code>/etc/initcpio/hooks/dropbear</code> e encontre/modifique a seguinte linha na função <code>run_hook()</code>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/initcpio/hooks/tinyssh</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;"> /usr/sbin/dropbear -E -s -j -k -p &lt;nova-porta&gt;
</pre>
<p><a href="../pt/Mkinitcpio.html#Cria%C3%A7%C3%A3o_e_ativa%C3%A7%C3%A3o_de_imagem" class="mw-redirect" title="Gere novamente o initramfs">Gere novamente o initramfs</a>.
</p>
<h4>
<span id="Desbloquear_.C3.A0_partir_de_uma_m.C3.A1quina_Windows_usando_PuTTY.2FPlink"></span><span class="mw-headline" id="Desbloquear_à_partir_de_uma_máquina_Windows_usando_PuTTY/Plink">Desbloquear à partir de uma máquina Windows usando PuTTY/Plink</span>
</h4>
<p>Primeiro, precisamos usar <code>puttygen.exe</code> para importar e converter a chave de OpenSSH gerada mais cedo para o formato de chave privada do PuTTY <i>.ppk</i>. No exemplo abaixo chamado de <code>zfs_abrir.ppk</code>
</p>
<p>O processo acima do mkinitcpio-netconf não configura um shell (mas não é necessário). No entanto, como não existe um shell, o PuTTY fechará imediatamente após uma conexão bem sucedida. Isto pode ser desabilitado na configuração de SSH do PuTTY (<i>Connection -&gt; SSH -&gt; [X] Do not start a shell or command at all</i>), mas ainda não permite enxergar a saída padrão (stdout) ou entrar a frase de criptografia. Em vez disso, usaremos o <code>plink.exe</code> com os seguintes parâmetros:
</p>
<pre>plink.exe -ssh -l root -i C:\caminho\pro\zfs_abrir.ppk &lt;hostname&gt;
</pre>
<p>O comando do plink pode ser inserido em um script em lotes para simplificar o uso.
</p>
<h2>
<span id="Veja_tamb.C3.A9m"></span><span class="mw-headline" id="Veja_também">Veja também</span>
</h2>
<ul>
<li><a rel="nofollow" class="external text" href="https://pthree.org/2012/12/04/zfs-administration-part-i-vdevs/">Aaron Toponce's 17-part blog on ZFS</a></li>
<li><a rel="nofollow" class="external text" href="https://zfsonlinux.org/">ZFS on Linux</a></li>
<li><a rel="nofollow" class="external text" href="https://github.com/zfsonlinux/zfs/wiki/faq">ZFS on Linux FAQ</a></li>
<li><a rel="nofollow" class="external text" href="https://www.freebsd.org/doc/pt_BR.ISO8859-1/books/handbook/zfs.html">FreeBSD Handbook - O sistema de arquivos Z</a></li>
<li><a rel="nofollow" class="external text" href="https://docs.oracle.com/cd/E19253-01/819-5461/index.html">Oracle Solaris ZFS Administration Guide</a></li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20161028084224/http://www.solarisinternals.com/wiki/index.php/ZFS_Best_Practices_Guide">ZFS Best Practices Guide</a></li>
<li><a rel="nofollow" class="external text" href="https://docs.oracle.com/cd/E23823_01/html/819-5461/gavwg.html">ZFS Troubleshooting Guide</a></li>
<li><a rel="nofollow" class="external text" href="https://www.linuxquestions.org/questions/linux-from-scratch-13/%5Bhow-to%5D-add-zfs-to-the-linux-Kernel-4175514510/">Tutorial on adding the modules to a custom Kernel</a></li>
<li><a rel="nofollow" class="external text" href="https://github.com/danboid/creating-ZFS-disks-under-Linux">How to create cross platform ZFS disks under Linux</a></li>
<li><a rel="nofollow" class="external text" href="https://blog.heckel.xyz/2017/01/08/zfs-encryption-openzfs-zfs-on-linux/">How-To: Using ZFS Encryption at Rest in OpenZFS (ZFS on Linux, ZFS on FreeBSD, …)</a></li>
</ul>
</div>
</div>
					<div id="catlinks" class="catlinks" data-mw="interface">
<div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="../Special:Categories.html" title="Special:Categories">Categories</a>: <ul>
<li><a href="../pt/Category:File_systems.html" title="Category:File systems (Português)">File systems (Português)</a></li>
<li><a href="../pt/Category:Oracle.html" title="Category:Oracle (Português)">Oracle (Português)</a></li>
</ul>
</div>
<div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden category: <ul><li><a href="../en/Category:Pages_with_broken_package_links.html" title="Category:Pages with broken package links">Pages with broken package links</a></li></ul>
</div>
</div>
				</div>
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" role="contentinfo" style="margin: 0">
	<ul id="footer-info">
	<li data-nosnippet="">Retrieved from "<a dir="ltr" href="https://wiki.archlinux.org/index.php?title=ZFS_(Portugu%C3%AAs)&amp;oldid=798810">https://wiki.archlinux.org/index.php?title=ZFS_(Português)&amp;oldid=798810</a>"</li>
<li id="footer-info-lastmod"> This page was last edited on 29 January 2024, at 08:22.</li>
	<li id="footer-info-copyright">Content is available under <a class="external" rel="nofollow" href="https://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License 1.3 or later</a> unless otherwise noted.</li>
<br>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://terms.archlinux.org/docs/privacy-policy/">Privacy policy</a></li>
	<li id="footer-places-about"><a href="../en/ArchWiki:About.html">About ArchWiki</a></li>
	<li id="footer-places-disclaimers"><a href="../en/ArchWiki:General_disclaimer.html">Disclaimers</a></li>
	<li id="footer-places-archwiki-code-of-conduct"><a href="https://terms.archlinux.org/docs/code-of-conduct/" class="extiw" title="archlinux-service-agreements:code-of-conduct">Code of conduct</a></li>
	<li id="footer-places-archwiki-terms-of-service"><a href="https://terms.archlinux.org/docs/terms-of-service/" class="extiw" title="archlinux-service-agreements:terms-of-service">Terms of service</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://www.gnu.org/copyleft/fdl.html"><img src="/resources/assets/licenses/gnu-fdl.png" alt="GNU Free Documentation License 1.3 or later" width="88" height="31" loading="lazy"></a></li>
	<li id="footer-poweredbyico"><img src="/resources/assets/poweredby_mediawiki_88x31.png" srcset="/resources/assets/poweredby_mediawiki_132x47.png 1.5x, /resources/assets/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"></li>
</ul>

</footer>

		</div>
	</div> 
</div> 
<div class="vector-settings" id="p-dock-bottom">
	<ul>
		<li>
		<button class="cdx-button cdx-button--icon-only vector-limited-width-toggle" id=""><span class="vector-icon mw-ui-icon-fullScreen mw-ui-icon-wikimedia-fullScreen"></span>

<span>Toggle limited content width</span>
</button>
</li>
	</ul>
</div>
</body>
</html>
